{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "titanic.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMSYI5kn9V69",
        "colab_type": "text"
      },
      "source": [
        "# Simple NN for survival prediction on the Titanic\n",
        "\n",
        "author: Witalis Domitrz <witekdomitrz@gmail.com>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NLkKLWma9wWn",
        "colab_type": "text"
      },
      "source": [
        "## Downloading the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VzlvCzL3jIGM",
        "colab_type": "code",
        "outputId": "8ec67e64-175e-4d50-b153-86b9d52b6939",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        }
      },
      "source": [
        "!wget http://students.mimuw.edu.pl/~wd393711/iml/titanic.zip\n",
        "!unzip -o titanic.zip\n",
        "!rm titanic.zip"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-03-08 22:29:24--  http://students.mimuw.edu.pl/~wd393711/iml/titanic.zip\n",
            "Resolving students.mimuw.edu.pl (students.mimuw.edu.pl)... 193.0.96.129, 2001:6a0:5001:1::3\n",
            "Connecting to students.mimuw.edu.pl (students.mimuw.edu.pl)|193.0.96.129|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 34877 (34K) [application/zip]\n",
            "Saving to: ‘titanic.zip’\n",
            "\n",
            "\rtitanic.zip           0%[                    ]       0  --.-KB/s               \rtitanic.zip         100%[===================>]  34.06K   222KB/s    in 0.2s    \n",
            "\n",
            "2020-03-08 22:29:25 (222 KB/s) - ‘titanic.zip’ saved [34877/34877]\n",
            "\n",
            "Archive:  titanic.zip\n",
            "  inflating: gender_submission.csv   \n",
            "  inflating: test.csv                \n",
            "  inflating: train.csv               \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGUsxBhT9zSc",
        "colab_type": "text"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j9_AmuWwgifh",
        "colab_type": "code",
        "outputId": "9ad0a1d0-956f-405c-b558-c2869d119ada",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import numpy as np \n",
        "import pandas as pd\n",
        "import tensorflow.keras.layers as layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adadelta\n",
        "from tensorflow.keras.callbacks import Callback"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "izJSfphJ94V-",
        "colab_type": "text"
      },
      "source": [
        "## Prepare the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVms9hm0r92r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_columns = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']\n",
        "Y_columns = ['Survived']\n",
        "\n",
        "def load_data(fn):\n",
        "    return pd.read_csv(fn).set_index('PassengerId')\n",
        "\n",
        "def to_array(data):\n",
        "    return pd.get_dummies(data).astype(dtype='float32').values\n",
        "\n",
        "def split_to_x_y(data):\n",
        "    return to_array(data[X_columns]), to_array(data[Y_columns])\n",
        "\n",
        "def get_data():\n",
        "    train = load_data('./train.csv')\n",
        "    test = load_data('./gender_submission.csv').join(load_data('./test.csv'))    \n",
        "\n",
        "    train['is_train'] = True\n",
        "    test['is_train'] = False\n",
        "    data = pd.concat([train, test])\n",
        "\n",
        "    # Replace missing values with mean\n",
        "    data.fillna(data.mean(), inplace=True)\n",
        "\n",
        "    # Split test and train\n",
        "    train = data[data['is_train']]\n",
        "    test = data[data['is_train'] == False]\n",
        "\n",
        "    return split_to_x_y(train), split_to_x_y(test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJStOTfynTPW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(train_x, train_y), (test_x, test_y) = get_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_lbDj9X9-kH",
        "colab_type": "text"
      },
      "source": [
        "## Create and train a model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mygb3eW5lDXq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_net():\n",
        "    model = Sequential()\n",
        "    for i in range(4):\n",
        "        model.add(layers.Dense(32, activation='relu'))\n",
        "        model.add(layers.BatchNormalization())\n",
        "        model.add(layers.Dense(24, activation='relu'))\n",
        "        model.add(layers.Dropout(0.5))\n",
        "        model.add(layers.BatchNormalization())\n",
        "    model.add(layers.Dense(1, activation='sigmoid'))\n",
        "    model.compile(loss='binary_crossentropy', optimizer = Adadelta(lr=1.), metrics = ['accuracy'])\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FhetoyGAxlG-",
        "colab_type": "code",
        "outputId": "25d9a5ab-d79e-485e-bf59-1ab0cf865375",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model = create_net()\n",
        "batch_size = 256\n",
        "training_history = model.fit(train_x, train_y, epochs=512, batch_size=batch_size, validation_split=0.2)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 712 samples, validate on 179 samples\n",
            "Epoch 1/512\n",
            "712/712 [==============================] - 2s 3ms/sample - loss: 0.8441 - accuracy: 0.5506 - val_loss: 0.8084 - val_accuracy: 0.3575\n",
            "Epoch 2/512\n",
            "712/712 [==============================] - 0s 41us/sample - loss: 0.8920 - accuracy: 0.5028 - val_loss: 0.7446 - val_accuracy: 0.3128\n",
            "Epoch 3/512\n",
            "712/712 [==============================] - 0s 39us/sample - loss: 0.8718 - accuracy: 0.5183 - val_loss: 0.7121 - val_accuracy: 0.3743\n",
            "Epoch 4/512\n",
            "712/712 [==============================] - 0s 41us/sample - loss: 0.8304 - accuracy: 0.5520 - val_loss: 0.6912 - val_accuracy: 0.4581\n",
            "Epoch 5/512\n",
            "712/712 [==============================] - 0s 41us/sample - loss: 0.8266 - accuracy: 0.5183 - val_loss: 0.6752 - val_accuracy: 0.6480\n",
            "Epoch 6/512\n",
            "712/712 [==============================] - 0s 39us/sample - loss: 0.8003 - accuracy: 0.5421 - val_loss: 0.6686 - val_accuracy: 0.7095\n",
            "Epoch 7/512\n",
            "712/712 [==============================] - 0s 35us/sample - loss: 0.8037 - accuracy: 0.5421 - val_loss: 0.6572 - val_accuracy: 0.6983\n",
            "Epoch 8/512\n",
            "712/712 [==============================] - 0s 40us/sample - loss: 0.7721 - accuracy: 0.5548 - val_loss: 0.6505 - val_accuracy: 0.6927\n",
            "Epoch 9/512\n",
            "712/712 [==============================] - 0s 37us/sample - loss: 0.8119 - accuracy: 0.5590 - val_loss: 0.6463 - val_accuracy: 0.6983\n",
            "Epoch 10/512\n",
            "712/712 [==============================] - 0s 37us/sample - loss: 0.7895 - accuracy: 0.5506 - val_loss: 0.6458 - val_accuracy: 0.6872\n",
            "Epoch 11/512\n",
            "712/712 [==============================] - 0s 38us/sample - loss: 0.8079 - accuracy: 0.5407 - val_loss: 0.6437 - val_accuracy: 0.6816\n",
            "Epoch 12/512\n",
            "712/712 [==============================] - 0s 35us/sample - loss: 0.8264 - accuracy: 0.5449 - val_loss: 0.6425 - val_accuracy: 0.6760\n",
            "Epoch 13/512\n",
            "712/712 [==============================] - 0s 34us/sample - loss: 0.7625 - accuracy: 0.5702 - val_loss: 0.6375 - val_accuracy: 0.6816\n",
            "Epoch 14/512\n",
            "712/712 [==============================] - 0s 44us/sample - loss: 0.7786 - accuracy: 0.5646 - val_loss: 0.6357 - val_accuracy: 0.6816\n",
            "Epoch 15/512\n",
            "712/712 [==============================] - 0s 38us/sample - loss: 0.7657 - accuracy: 0.5632 - val_loss: 0.6324 - val_accuracy: 0.6816\n",
            "Epoch 16/512\n",
            "712/712 [==============================] - 0s 42us/sample - loss: 0.7658 - accuracy: 0.5702 - val_loss: 0.6308 - val_accuracy: 0.6816\n",
            "Epoch 17/512\n",
            "712/712 [==============================] - 0s 36us/sample - loss: 0.7580 - accuracy: 0.6011 - val_loss: 0.6315 - val_accuracy: 0.6816\n",
            "Epoch 18/512\n",
            "712/712 [==============================] - 0s 40us/sample - loss: 0.7933 - accuracy: 0.5590 - val_loss: 0.6350 - val_accuracy: 0.6760\n",
            "Epoch 19/512\n",
            "712/712 [==============================] - 0s 40us/sample - loss: 0.7451 - accuracy: 0.5885 - val_loss: 0.6363 - val_accuracy: 0.6760\n",
            "Epoch 20/512\n",
            "712/712 [==============================] - 0s 37us/sample - loss: 0.7192 - accuracy: 0.5955 - val_loss: 0.6344 - val_accuracy: 0.6760\n",
            "Epoch 21/512\n",
            "712/712 [==============================] - 0s 37us/sample - loss: 0.7118 - accuracy: 0.6208 - val_loss: 0.6365 - val_accuracy: 0.6704\n",
            "Epoch 22/512\n",
            "712/712 [==============================] - 0s 38us/sample - loss: 0.7326 - accuracy: 0.5730 - val_loss: 0.6377 - val_accuracy: 0.6704\n",
            "Epoch 23/512\n",
            "712/712 [==============================] - 0s 42us/sample - loss: 0.7341 - accuracy: 0.5885 - val_loss: 0.6344 - val_accuracy: 0.6760\n",
            "Epoch 24/512\n",
            "712/712 [==============================] - 0s 38us/sample - loss: 0.7524 - accuracy: 0.5618 - val_loss: 0.6350 - val_accuracy: 0.6760\n",
            "Epoch 25/512\n",
            "712/712 [==============================] - 0s 37us/sample - loss: 0.7533 - accuracy: 0.5997 - val_loss: 0.6391 - val_accuracy: 0.6704\n",
            "Epoch 26/512\n",
            "712/712 [==============================] - 0s 36us/sample - loss: 0.7559 - accuracy: 0.5871 - val_loss: 0.6409 - val_accuracy: 0.6704\n",
            "Epoch 27/512\n",
            "712/712 [==============================] - 0s 37us/sample - loss: 0.7525 - accuracy: 0.6039 - val_loss: 0.6359 - val_accuracy: 0.6704\n",
            "Epoch 28/512\n",
            "712/712 [==============================] - 0s 49us/sample - loss: 0.6979 - accuracy: 0.6138 - val_loss: 0.6347 - val_accuracy: 0.6760\n",
            "Epoch 29/512\n",
            "712/712 [==============================] - 0s 46us/sample - loss: 0.7120 - accuracy: 0.6011 - val_loss: 0.6323 - val_accuracy: 0.6760\n",
            "Epoch 30/512\n",
            "712/712 [==============================] - 0s 42us/sample - loss: 0.7248 - accuracy: 0.5660 - val_loss: 0.6343 - val_accuracy: 0.6760\n",
            "Epoch 31/512\n",
            "712/712 [==============================] - 0s 34us/sample - loss: 0.7000 - accuracy: 0.6067 - val_loss: 0.6324 - val_accuracy: 0.6760\n",
            "Epoch 32/512\n",
            "712/712 [==============================] - 0s 34us/sample - loss: 0.7199 - accuracy: 0.5997 - val_loss: 0.6344 - val_accuracy: 0.6760\n",
            "Epoch 33/512\n",
            "712/712 [==============================] - 0s 45us/sample - loss: 0.7347 - accuracy: 0.5983 - val_loss: 0.6351 - val_accuracy: 0.6760\n",
            "Epoch 34/512\n",
            "712/712 [==============================] - 0s 41us/sample - loss: 0.7227 - accuracy: 0.5843 - val_loss: 0.6336 - val_accuracy: 0.6760\n",
            "Epoch 35/512\n",
            "712/712 [==============================] - 0s 43us/sample - loss: 0.7035 - accuracy: 0.6278 - val_loss: 0.6309 - val_accuracy: 0.6760\n",
            "Epoch 36/512\n",
            "712/712 [==============================] - 0s 38us/sample - loss: 0.7161 - accuracy: 0.6025 - val_loss: 0.6262 - val_accuracy: 0.6760\n",
            "Epoch 37/512\n",
            "712/712 [==============================] - 0s 36us/sample - loss: 0.7085 - accuracy: 0.6067 - val_loss: 0.6275 - val_accuracy: 0.6760\n",
            "Epoch 38/512\n",
            "712/712 [==============================] - 0s 38us/sample - loss: 0.6914 - accuracy: 0.6320 - val_loss: 0.6267 - val_accuracy: 0.6760\n",
            "Epoch 39/512\n",
            "712/712 [==============================] - 0s 38us/sample - loss: 0.7199 - accuracy: 0.5730 - val_loss: 0.6277 - val_accuracy: 0.6760\n",
            "Epoch 40/512\n",
            "712/712 [==============================] - 0s 41us/sample - loss: 0.7113 - accuracy: 0.6081 - val_loss: 0.6249 - val_accuracy: 0.6760\n",
            "Epoch 41/512\n",
            "712/712 [==============================] - 0s 43us/sample - loss: 0.7205 - accuracy: 0.5871 - val_loss: 0.6229 - val_accuracy: 0.6760\n",
            "Epoch 42/512\n",
            "712/712 [==============================] - 0s 36us/sample - loss: 0.6977 - accuracy: 0.6152 - val_loss: 0.6232 - val_accuracy: 0.6760\n",
            "Epoch 43/512\n",
            "712/712 [==============================] - 0s 38us/sample - loss: 0.6922 - accuracy: 0.6180 - val_loss: 0.6219 - val_accuracy: 0.6760\n",
            "Epoch 44/512\n",
            "712/712 [==============================] - 0s 36us/sample - loss: 0.7414 - accuracy: 0.5801 - val_loss: 0.6232 - val_accuracy: 0.6760\n",
            "Epoch 45/512\n",
            "712/712 [==============================] - 0s 36us/sample - loss: 0.7071 - accuracy: 0.6011 - val_loss: 0.6238 - val_accuracy: 0.6760\n",
            "Epoch 46/512\n",
            "712/712 [==============================] - 0s 38us/sample - loss: 0.7339 - accuracy: 0.5772 - val_loss: 0.6253 - val_accuracy: 0.6760\n",
            "Epoch 47/512\n",
            "712/712 [==============================] - 0s 36us/sample - loss: 0.7056 - accuracy: 0.6053 - val_loss: 0.6282 - val_accuracy: 0.6760\n",
            "Epoch 48/512\n",
            "712/712 [==============================] - 0s 36us/sample - loss: 0.7100 - accuracy: 0.6096 - val_loss: 0.6314 - val_accuracy: 0.6760\n",
            "Epoch 49/512\n",
            "712/712 [==============================] - 0s 38us/sample - loss: 0.7088 - accuracy: 0.6081 - val_loss: 0.6326 - val_accuracy: 0.6760\n",
            "Epoch 50/512\n",
            "712/712 [==============================] - 0s 43us/sample - loss: 0.6769 - accuracy: 0.6320 - val_loss: 0.6310 - val_accuracy: 0.6760\n",
            "Epoch 51/512\n",
            "712/712 [==============================] - 0s 37us/sample - loss: 0.7163 - accuracy: 0.6025 - val_loss: 0.6291 - val_accuracy: 0.6760\n",
            "Epoch 52/512\n",
            "712/712 [==============================] - 0s 32us/sample - loss: 0.7125 - accuracy: 0.6124 - val_loss: 0.6296 - val_accuracy: 0.6760\n",
            "Epoch 53/512\n",
            "712/712 [==============================] - 0s 45us/sample - loss: 0.6725 - accuracy: 0.6208 - val_loss: 0.6283 - val_accuracy: 0.6760\n",
            "Epoch 54/512\n",
            "712/712 [==============================] - 0s 40us/sample - loss: 0.6899 - accuracy: 0.6124 - val_loss: 0.6264 - val_accuracy: 0.6760\n",
            "Epoch 55/512\n",
            "712/712 [==============================] - 0s 40us/sample - loss: 0.7035 - accuracy: 0.6081 - val_loss: 0.6265 - val_accuracy: 0.6760\n",
            "Epoch 56/512\n",
            "712/712 [==============================] - 0s 40us/sample - loss: 0.7202 - accuracy: 0.6138 - val_loss: 0.6298 - val_accuracy: 0.6760\n",
            "Epoch 57/512\n",
            "712/712 [==============================] - 0s 40us/sample - loss: 0.6973 - accuracy: 0.6067 - val_loss: 0.6304 - val_accuracy: 0.6760\n",
            "Epoch 58/512\n",
            "712/712 [==============================] - 0s 38us/sample - loss: 0.6955 - accuracy: 0.6180 - val_loss: 0.6301 - val_accuracy: 0.6760\n",
            "Epoch 59/512\n",
            "712/712 [==============================] - 0s 35us/sample - loss: 0.7169 - accuracy: 0.5927 - val_loss: 0.6297 - val_accuracy: 0.6760\n",
            "Epoch 60/512\n",
            "712/712 [==============================] - 0s 35us/sample - loss: 0.7280 - accuracy: 0.5857 - val_loss: 0.6293 - val_accuracy: 0.6760\n",
            "Epoch 61/512\n",
            "712/712 [==============================] - 0s 39us/sample - loss: 0.6964 - accuracy: 0.6222 - val_loss: 0.6290 - val_accuracy: 0.6760\n",
            "Epoch 62/512\n",
            "712/712 [==============================] - 0s 42us/sample - loss: 0.7265 - accuracy: 0.5885 - val_loss: 0.6280 - val_accuracy: 0.6760\n",
            "Epoch 63/512\n",
            "712/712 [==============================] - 0s 41us/sample - loss: 0.6883 - accuracy: 0.6025 - val_loss: 0.6291 - val_accuracy: 0.6760\n",
            "Epoch 64/512\n",
            "712/712 [==============================] - 0s 40us/sample - loss: 0.6957 - accuracy: 0.6053 - val_loss: 0.6278 - val_accuracy: 0.6760\n",
            "Epoch 65/512\n",
            "712/712 [==============================] - 0s 41us/sample - loss: 0.7082 - accuracy: 0.6011 - val_loss: 0.6250 - val_accuracy: 0.6760\n",
            "Epoch 66/512\n",
            "712/712 [==============================] - 0s 38us/sample - loss: 0.7061 - accuracy: 0.6025 - val_loss: 0.6220 - val_accuracy: 0.6760\n",
            "Epoch 67/512\n",
            "712/712 [==============================] - 0s 38us/sample - loss: 0.6983 - accuracy: 0.6166 - val_loss: 0.6207 - val_accuracy: 0.6816\n",
            "Epoch 68/512\n",
            "712/712 [==============================] - 0s 36us/sample - loss: 0.6883 - accuracy: 0.6138 - val_loss: 0.6215 - val_accuracy: 0.6816\n",
            "Epoch 69/512\n",
            "712/712 [==============================] - 0s 40us/sample - loss: 0.6722 - accuracy: 0.6166 - val_loss: 0.6223 - val_accuracy: 0.6816\n",
            "Epoch 70/512\n",
            "712/712 [==============================] - 0s 45us/sample - loss: 0.6940 - accuracy: 0.6180 - val_loss: 0.6229 - val_accuracy: 0.6816\n",
            "Epoch 71/512\n",
            "712/712 [==============================] - 0s 39us/sample - loss: 0.6982 - accuracy: 0.6110 - val_loss: 0.6248 - val_accuracy: 0.6760\n",
            "Epoch 72/512\n",
            "712/712 [==============================] - 0s 38us/sample - loss: 0.6739 - accuracy: 0.6334 - val_loss: 0.6244 - val_accuracy: 0.6760\n",
            "Epoch 73/512\n",
            "712/712 [==============================] - 0s 38us/sample - loss: 0.6824 - accuracy: 0.6222 - val_loss: 0.6236 - val_accuracy: 0.6816\n",
            "Epoch 74/512\n",
            "712/712 [==============================] - 0s 38us/sample - loss: 0.6891 - accuracy: 0.6081 - val_loss: 0.6236 - val_accuracy: 0.6760\n",
            "Epoch 75/512\n",
            "712/712 [==============================] - 0s 41us/sample - loss: 0.6550 - accuracy: 0.6433 - val_loss: 0.6220 - val_accuracy: 0.6816\n",
            "Epoch 76/512\n",
            "712/712 [==============================] - 0s 37us/sample - loss: 0.6589 - accuracy: 0.6433 - val_loss: 0.6213 - val_accuracy: 0.6816\n",
            "Epoch 77/512\n",
            "712/712 [==============================] - 0s 39us/sample - loss: 0.6713 - accuracy: 0.6419 - val_loss: 0.6206 - val_accuracy: 0.6760\n",
            "Epoch 78/512\n",
            "712/712 [==============================] - 0s 43us/sample - loss: 0.7011 - accuracy: 0.6096 - val_loss: 0.6213 - val_accuracy: 0.6816\n",
            "Epoch 79/512\n",
            "712/712 [==============================] - 0s 39us/sample - loss: 0.6821 - accuracy: 0.6236 - val_loss: 0.6196 - val_accuracy: 0.6816\n",
            "Epoch 80/512\n",
            "712/712 [==============================] - 0s 35us/sample - loss: 0.6605 - accuracy: 0.6306 - val_loss: 0.6194 - val_accuracy: 0.6816\n",
            "Epoch 81/512\n",
            "712/712 [==============================] - 0s 37us/sample - loss: 0.6901 - accuracy: 0.6250 - val_loss: 0.6207 - val_accuracy: 0.6816\n",
            "Epoch 82/512\n",
            "712/712 [==============================] - 0s 37us/sample - loss: 0.6655 - accuracy: 0.6236 - val_loss: 0.6208 - val_accuracy: 0.6816\n",
            "Epoch 83/512\n",
            "712/712 [==============================] - 0s 36us/sample - loss: 0.6897 - accuracy: 0.6039 - val_loss: 0.6184 - val_accuracy: 0.6872\n",
            "Epoch 84/512\n",
            "712/712 [==============================] - 0s 46us/sample - loss: 0.6940 - accuracy: 0.6376 - val_loss: 0.6188 - val_accuracy: 0.6872\n",
            "Epoch 85/512\n",
            "712/712 [==============================] - 0s 36us/sample - loss: 0.6860 - accuracy: 0.6110 - val_loss: 0.6183 - val_accuracy: 0.6872\n",
            "Epoch 86/512\n",
            "712/712 [==============================] - 0s 36us/sample - loss: 0.6860 - accuracy: 0.6180 - val_loss: 0.6181 - val_accuracy: 0.6872\n",
            "Epoch 87/512\n",
            "712/712 [==============================] - 0s 37us/sample - loss: 0.6654 - accuracy: 0.6447 - val_loss: 0.6184 - val_accuracy: 0.6872\n",
            "Epoch 88/512\n",
            "712/712 [==============================] - 0s 36us/sample - loss: 0.6906 - accuracy: 0.6334 - val_loss: 0.6176 - val_accuracy: 0.6872\n",
            "Epoch 89/512\n",
            "712/712 [==============================] - 0s 36us/sample - loss: 0.6720 - accuracy: 0.6208 - val_loss: 0.6174 - val_accuracy: 0.6872\n",
            "Epoch 90/512\n",
            "712/712 [==============================] - 0s 38us/sample - loss: 0.6838 - accuracy: 0.6138 - val_loss: 0.6168 - val_accuracy: 0.6872\n",
            "Epoch 91/512\n",
            "712/712 [==============================] - 0s 43us/sample - loss: 0.6711 - accuracy: 0.6292 - val_loss: 0.6152 - val_accuracy: 0.6872\n",
            "Epoch 92/512\n",
            "712/712 [==============================] - 0s 39us/sample - loss: 0.6693 - accuracy: 0.6348 - val_loss: 0.6149 - val_accuracy: 0.6872\n",
            "Epoch 93/512\n",
            "712/712 [==============================] - 0s 40us/sample - loss: 0.6972 - accuracy: 0.6180 - val_loss: 0.6169 - val_accuracy: 0.6872\n",
            "Epoch 94/512\n",
            "712/712 [==============================] - 0s 35us/sample - loss: 0.6754 - accuracy: 0.6264 - val_loss: 0.6192 - val_accuracy: 0.6872\n",
            "Epoch 95/512\n",
            "712/712 [==============================] - 0s 44us/sample - loss: 0.6739 - accuracy: 0.6180 - val_loss: 0.6175 - val_accuracy: 0.6872\n",
            "Epoch 96/512\n",
            "712/712 [==============================] - 0s 41us/sample - loss: 0.6528 - accuracy: 0.6461 - val_loss: 0.6158 - val_accuracy: 0.6872\n",
            "Epoch 97/512\n",
            "712/712 [==============================] - 0s 46us/sample - loss: 0.6620 - accuracy: 0.6264 - val_loss: 0.6164 - val_accuracy: 0.6872\n",
            "Epoch 98/512\n",
            "712/712 [==============================] - 0s 36us/sample - loss: 0.6741 - accuracy: 0.6124 - val_loss: 0.6149 - val_accuracy: 0.6872\n",
            "Epoch 99/512\n",
            "712/712 [==============================] - 0s 36us/sample - loss: 0.6704 - accuracy: 0.6390 - val_loss: 0.6139 - val_accuracy: 0.6872\n",
            "Epoch 100/512\n",
            "712/712 [==============================] - 0s 38us/sample - loss: 0.6666 - accuracy: 0.6292 - val_loss: 0.6135 - val_accuracy: 0.6872\n",
            "Epoch 101/512\n",
            "712/712 [==============================] - 0s 36us/sample - loss: 0.6727 - accuracy: 0.6208 - val_loss: 0.6131 - val_accuracy: 0.6872\n",
            "Epoch 102/512\n",
            "712/712 [==============================] - 0s 37us/sample - loss: 0.6723 - accuracy: 0.6250 - val_loss: 0.6127 - val_accuracy: 0.6872\n",
            "Epoch 103/512\n",
            "712/712 [==============================] - 0s 46us/sample - loss: 0.6612 - accuracy: 0.6320 - val_loss: 0.6124 - val_accuracy: 0.6927\n",
            "Epoch 104/512\n",
            "712/712 [==============================] - 0s 38us/sample - loss: 0.6794 - accuracy: 0.6180 - val_loss: 0.6148 - val_accuracy: 0.6872\n",
            "Epoch 105/512\n",
            "712/712 [==============================] - 0s 42us/sample - loss: 0.6520 - accuracy: 0.6250 - val_loss: 0.6141 - val_accuracy: 0.6927\n",
            "Epoch 106/512\n",
            "712/712 [==============================] - 0s 43us/sample - loss: 0.6751 - accuracy: 0.6292 - val_loss: 0.6133 - val_accuracy: 0.6927\n",
            "Epoch 107/512\n",
            "712/712 [==============================] - 0s 34us/sample - loss: 0.6706 - accuracy: 0.6390 - val_loss: 0.6131 - val_accuracy: 0.6872\n",
            "Epoch 108/512\n",
            "712/712 [==============================] - 0s 37us/sample - loss: 0.6876 - accuracy: 0.6236 - val_loss: 0.6123 - val_accuracy: 0.6927\n",
            "Epoch 109/512\n",
            "712/712 [==============================] - 0s 39us/sample - loss: 0.6785 - accuracy: 0.6222 - val_loss: 0.6118 - val_accuracy: 0.6927\n",
            "Epoch 110/512\n",
            "712/712 [==============================] - 0s 43us/sample - loss: 0.6688 - accuracy: 0.6222 - val_loss: 0.6128 - val_accuracy: 0.6872\n",
            "Epoch 111/512\n",
            "712/712 [==============================] - 0s 39us/sample - loss: 0.6617 - accuracy: 0.6362 - val_loss: 0.6141 - val_accuracy: 0.6872\n",
            "Epoch 112/512\n",
            "712/712 [==============================] - 0s 45us/sample - loss: 0.6470 - accuracy: 0.6503 - val_loss: 0.6116 - val_accuracy: 0.6927\n",
            "Epoch 113/512\n",
            "712/712 [==============================] - 0s 35us/sample - loss: 0.6639 - accuracy: 0.6419 - val_loss: 0.6113 - val_accuracy: 0.6983\n",
            "Epoch 114/512\n",
            "712/712 [==============================] - 0s 38us/sample - loss: 0.6647 - accuracy: 0.6376 - val_loss: 0.6093 - val_accuracy: 0.6983\n",
            "Epoch 115/512\n",
            "712/712 [==============================] - 0s 40us/sample - loss: 0.6515 - accuracy: 0.6306 - val_loss: 0.6074 - val_accuracy: 0.7039\n",
            "Epoch 116/512\n",
            "712/712 [==============================] - 0s 37us/sample - loss: 0.6618 - accuracy: 0.6306 - val_loss: 0.6077 - val_accuracy: 0.7039\n",
            "Epoch 117/512\n",
            "712/712 [==============================] - 0s 39us/sample - loss: 0.6631 - accuracy: 0.6433 - val_loss: 0.6082 - val_accuracy: 0.6983\n",
            "Epoch 118/512\n",
            "712/712 [==============================] - 0s 38us/sample - loss: 0.6522 - accuracy: 0.6334 - val_loss: 0.6072 - val_accuracy: 0.7039\n",
            "Epoch 119/512\n",
            "712/712 [==============================] - 0s 38us/sample - loss: 0.6521 - accuracy: 0.6419 - val_loss: 0.6057 - val_accuracy: 0.7095\n",
            "Epoch 120/512\n",
            "712/712 [==============================] - 0s 40us/sample - loss: 0.6613 - accuracy: 0.6152 - val_loss: 0.6043 - val_accuracy: 0.7095\n",
            "Epoch 121/512\n",
            "712/712 [==============================] - 0s 42us/sample - loss: 0.6509 - accuracy: 0.6376 - val_loss: 0.6039 - val_accuracy: 0.7095\n",
            "Epoch 122/512\n",
            "712/712 [==============================] - 0s 42us/sample - loss: 0.6687 - accuracy: 0.6348 - val_loss: 0.6010 - val_accuracy: 0.7039\n",
            "Epoch 123/512\n",
            "712/712 [==============================] - 0s 39us/sample - loss: 0.6546 - accuracy: 0.6376 - val_loss: 0.6012 - val_accuracy: 0.7039\n",
            "Epoch 124/512\n",
            "712/712 [==============================] - 0s 38us/sample - loss: 0.6483 - accuracy: 0.6531 - val_loss: 0.6014 - val_accuracy: 0.7039\n",
            "Epoch 125/512\n",
            "712/712 [==============================] - 0s 40us/sample - loss: 0.6405 - accuracy: 0.6475 - val_loss: 0.6012 - val_accuracy: 0.7039\n",
            "Epoch 126/512\n",
            "712/712 [==============================] - 0s 41us/sample - loss: 0.6627 - accuracy: 0.6362 - val_loss: 0.5997 - val_accuracy: 0.7039\n",
            "Epoch 127/512\n",
            "712/712 [==============================] - 0s 31us/sample - loss: 0.6514 - accuracy: 0.6475 - val_loss: 0.5989 - val_accuracy: 0.7039\n",
            "Epoch 128/512\n",
            "712/712 [==============================] - 0s 37us/sample - loss: 0.6606 - accuracy: 0.6320 - val_loss: 0.5984 - val_accuracy: 0.7039\n",
            "Epoch 129/512\n",
            "712/712 [==============================] - 0s 36us/sample - loss: 0.6542 - accuracy: 0.6376 - val_loss: 0.5987 - val_accuracy: 0.7039\n",
            "Epoch 130/512\n",
            "712/712 [==============================] - 0s 37us/sample - loss: 0.6527 - accuracy: 0.6404 - val_loss: 0.5985 - val_accuracy: 0.7039\n",
            "Epoch 131/512\n",
            "712/712 [==============================] - 0s 37us/sample - loss: 0.6514 - accuracy: 0.6390 - val_loss: 0.5972 - val_accuracy: 0.7039\n",
            "Epoch 132/512\n",
            "712/712 [==============================] - 0s 46us/sample - loss: 0.6481 - accuracy: 0.6404 - val_loss: 0.5961 - val_accuracy: 0.7151\n",
            "Epoch 133/512\n",
            "712/712 [==============================] - 0s 39us/sample - loss: 0.6494 - accuracy: 0.6657 - val_loss: 0.5960 - val_accuracy: 0.7095\n",
            "Epoch 134/512\n",
            "712/712 [==============================] - 0s 44us/sample - loss: 0.6572 - accuracy: 0.6348 - val_loss: 0.5980 - val_accuracy: 0.7039\n",
            "Epoch 135/512\n",
            "712/712 [==============================] - 0s 38us/sample - loss: 0.6731 - accuracy: 0.6461 - val_loss: 0.5966 - val_accuracy: 0.7039\n",
            "Epoch 136/512\n",
            "712/712 [==============================] - 0s 39us/sample - loss: 0.6563 - accuracy: 0.6376 - val_loss: 0.5981 - val_accuracy: 0.7039\n",
            "Epoch 137/512\n",
            "712/712 [==============================] - 0s 42us/sample - loss: 0.6547 - accuracy: 0.6320 - val_loss: 0.5986 - val_accuracy: 0.7095\n",
            "Epoch 138/512\n",
            "712/712 [==============================] - 0s 37us/sample - loss: 0.6492 - accuracy: 0.6334 - val_loss: 0.5971 - val_accuracy: 0.7039\n",
            "Epoch 139/512\n",
            "712/712 [==============================] - 0s 39us/sample - loss: 0.6647 - accuracy: 0.6306 - val_loss: 0.5976 - val_accuracy: 0.7095\n",
            "Epoch 140/512\n",
            "712/712 [==============================] - 0s 37us/sample - loss: 0.6494 - accuracy: 0.6404 - val_loss: 0.5947 - val_accuracy: 0.7151\n",
            "Epoch 141/512\n",
            "712/712 [==============================] - 0s 37us/sample - loss: 0.6397 - accuracy: 0.6517 - val_loss: 0.5923 - val_accuracy: 0.7151\n",
            "Epoch 142/512\n",
            "712/712 [==============================] - 0s 39us/sample - loss: 0.6547 - accuracy: 0.6334 - val_loss: 0.5912 - val_accuracy: 0.7151\n",
            "Epoch 143/512\n",
            "712/712 [==============================] - 0s 35us/sample - loss: 0.6635 - accuracy: 0.6264 - val_loss: 0.5912 - val_accuracy: 0.7151\n",
            "Epoch 144/512\n",
            "712/712 [==============================] - 0s 37us/sample - loss: 0.6435 - accuracy: 0.6461 - val_loss: 0.5905 - val_accuracy: 0.7151\n",
            "Epoch 145/512\n",
            "712/712 [==============================] - 0s 45us/sample - loss: 0.6536 - accuracy: 0.6447 - val_loss: 0.5930 - val_accuracy: 0.7039\n",
            "Epoch 146/512\n",
            "712/712 [==============================] - 0s 37us/sample - loss: 0.6427 - accuracy: 0.6489 - val_loss: 0.5924 - val_accuracy: 0.7039\n",
            "Epoch 147/512\n",
            "712/712 [==============================] - 0s 38us/sample - loss: 0.6529 - accuracy: 0.6334 - val_loss: 0.5908 - val_accuracy: 0.7039\n",
            "Epoch 148/512\n",
            "712/712 [==============================] - 0s 38us/sample - loss: 0.6618 - accuracy: 0.6264 - val_loss: 0.5886 - val_accuracy: 0.7151\n",
            "Epoch 149/512\n",
            "712/712 [==============================] - 0s 38us/sample - loss: 0.6409 - accuracy: 0.6390 - val_loss: 0.5890 - val_accuracy: 0.7039\n",
            "Epoch 150/512\n",
            "712/712 [==============================] - 0s 36us/sample - loss: 0.6482 - accuracy: 0.6601 - val_loss: 0.5900 - val_accuracy: 0.7095\n",
            "Epoch 151/512\n",
            "712/712 [==============================] - 0s 36us/sample - loss: 0.6510 - accuracy: 0.6545 - val_loss: 0.5893 - val_accuracy: 0.7039\n",
            "Epoch 152/512\n",
            "712/712 [==============================] - 0s 37us/sample - loss: 0.6439 - accuracy: 0.6404 - val_loss: 0.5871 - val_accuracy: 0.7095\n",
            "Epoch 153/512\n",
            "712/712 [==============================] - 0s 35us/sample - loss: 0.6465 - accuracy: 0.6601 - val_loss: 0.5860 - val_accuracy: 0.7095\n",
            "Epoch 154/512\n",
            "712/712 [==============================] - 0s 45us/sample - loss: 0.6336 - accuracy: 0.6643 - val_loss: 0.5855 - val_accuracy: 0.7095\n",
            "Epoch 155/512\n",
            "712/712 [==============================] - 0s 40us/sample - loss: 0.6413 - accuracy: 0.6601 - val_loss: 0.5836 - val_accuracy: 0.7095\n",
            "Epoch 156/512\n",
            "712/712 [==============================] - 0s 45us/sample - loss: 0.6327 - accuracy: 0.6559 - val_loss: 0.5816 - val_accuracy: 0.7095\n",
            "Epoch 157/512\n",
            "712/712 [==============================] - 0s 39us/sample - loss: 0.6402 - accuracy: 0.6503 - val_loss: 0.5769 - val_accuracy: 0.7095\n",
            "Epoch 158/512\n",
            "712/712 [==============================] - 0s 35us/sample - loss: 0.6304 - accuracy: 0.6587 - val_loss: 0.5737 - val_accuracy: 0.7151\n",
            "Epoch 159/512\n",
            "712/712 [==============================] - 0s 35us/sample - loss: 0.6341 - accuracy: 0.6601 - val_loss: 0.5811 - val_accuracy: 0.6983\n",
            "Epoch 160/512\n",
            "712/712 [==============================] - 0s 36us/sample - loss: 0.6256 - accuracy: 0.6699 - val_loss: 0.5686 - val_accuracy: 0.7207\n",
            "Epoch 161/512\n",
            "712/712 [==============================] - 0s 38us/sample - loss: 0.6171 - accuracy: 0.6671 - val_loss: 0.5749 - val_accuracy: 0.7151\n",
            "Epoch 162/512\n",
            "712/712 [==============================] - 0s 46us/sample - loss: 0.6222 - accuracy: 0.6601 - val_loss: 0.5643 - val_accuracy: 0.7207\n",
            "Epoch 163/512\n",
            "712/712 [==============================] - 0s 37us/sample - loss: 0.6221 - accuracy: 0.6573 - val_loss: 0.5745 - val_accuracy: 0.7151\n",
            "Epoch 164/512\n",
            "712/712 [==============================] - 0s 43us/sample - loss: 0.6299 - accuracy: 0.6629 - val_loss: 0.5832 - val_accuracy: 0.6927\n",
            "Epoch 165/512\n",
            "712/712 [==============================] - 0s 41us/sample - loss: 0.6368 - accuracy: 0.6629 - val_loss: 0.5716 - val_accuracy: 0.7151\n",
            "Epoch 166/512\n",
            "712/712 [==============================] - 0s 40us/sample - loss: 0.6163 - accuracy: 0.6812 - val_loss: 0.5656 - val_accuracy: 0.7151\n",
            "Epoch 167/512\n",
            "712/712 [==============================] - 0s 36us/sample - loss: 0.6144 - accuracy: 0.6784 - val_loss: 0.5552 - val_accuracy: 0.7207\n",
            "Epoch 168/512\n",
            "712/712 [==============================] - 0s 36us/sample - loss: 0.6103 - accuracy: 0.6671 - val_loss: 0.5594 - val_accuracy: 0.7207\n",
            "Epoch 169/512\n",
            "712/712 [==============================] - 0s 37us/sample - loss: 0.6160 - accuracy: 0.6784 - val_loss: 0.5762 - val_accuracy: 0.6927\n",
            "Epoch 170/512\n",
            "712/712 [==============================] - 0s 38us/sample - loss: 0.6219 - accuracy: 0.6784 - val_loss: 0.5687 - val_accuracy: 0.7039\n",
            "Epoch 171/512\n",
            "712/712 [==============================] - 0s 38us/sample - loss: 0.6065 - accuracy: 0.6713 - val_loss: 0.5481 - val_accuracy: 0.7263\n",
            "Epoch 172/512\n",
            "712/712 [==============================] - 0s 46us/sample - loss: 0.6149 - accuracy: 0.6587 - val_loss: 0.5462 - val_accuracy: 0.7263\n",
            "Epoch 173/512\n",
            "712/712 [==============================] - 0s 40us/sample - loss: 0.6007 - accuracy: 0.6868 - val_loss: 0.5380 - val_accuracy: 0.7374\n",
            "Epoch 174/512\n",
            "712/712 [==============================] - 0s 42us/sample - loss: 0.5971 - accuracy: 0.6896 - val_loss: 0.5445 - val_accuracy: 0.7151\n",
            "Epoch 175/512\n",
            "712/712 [==============================] - 0s 43us/sample - loss: 0.6142 - accuracy: 0.6756 - val_loss: 0.5363 - val_accuracy: 0.7374\n",
            "Epoch 176/512\n",
            "712/712 [==============================] - 0s 42us/sample - loss: 0.6007 - accuracy: 0.6840 - val_loss: 0.5543 - val_accuracy: 0.7151\n",
            "Epoch 177/512\n",
            "712/712 [==============================] - 0s 37us/sample - loss: 0.5924 - accuracy: 0.7163 - val_loss: 0.5569 - val_accuracy: 0.6983\n",
            "Epoch 178/512\n",
            "712/712 [==============================] - 0s 38us/sample - loss: 0.5899 - accuracy: 0.6980 - val_loss: 0.5362 - val_accuracy: 0.7263\n",
            "Epoch 179/512\n",
            "712/712 [==============================] - 0s 39us/sample - loss: 0.5706 - accuracy: 0.7191 - val_loss: 0.5300 - val_accuracy: 0.7374\n",
            "Epoch 180/512\n",
            "712/712 [==============================] - 0s 34us/sample - loss: 0.5770 - accuracy: 0.7037 - val_loss: 0.5112 - val_accuracy: 0.7821\n",
            "Epoch 181/512\n",
            "712/712 [==============================] - 0s 36us/sample - loss: 0.5877 - accuracy: 0.7149 - val_loss: 0.5653 - val_accuracy: 0.6927\n",
            "Epoch 182/512\n",
            "712/712 [==============================] - 0s 45us/sample - loss: 0.5523 - accuracy: 0.7317 - val_loss: 0.5355 - val_accuracy: 0.7486\n",
            "Epoch 183/512\n",
            "712/712 [==============================] - 0s 38us/sample - loss: 0.5748 - accuracy: 0.7219 - val_loss: 0.5176 - val_accuracy: 0.7654\n",
            "Epoch 184/512\n",
            "712/712 [==============================] - 0s 41us/sample - loss: 0.5889 - accuracy: 0.7079 - val_loss: 0.5063 - val_accuracy: 0.7877\n",
            "Epoch 185/512\n",
            "712/712 [==============================] - 0s 49us/sample - loss: 0.5865 - accuracy: 0.6952 - val_loss: 0.4902 - val_accuracy: 0.7933\n",
            "Epoch 186/512\n",
            "712/712 [==============================] - 0s 34us/sample - loss: 0.5687 - accuracy: 0.7191 - val_loss: 0.4892 - val_accuracy: 0.7821\n",
            "Epoch 187/512\n",
            "712/712 [==============================] - 0s 37us/sample - loss: 0.5786 - accuracy: 0.7149 - val_loss: 0.4840 - val_accuracy: 0.7877\n",
            "Epoch 188/512\n",
            "712/712 [==============================] - 0s 38us/sample - loss: 0.5463 - accuracy: 0.7317 - val_loss: 0.5165 - val_accuracy: 0.7877\n",
            "Epoch 189/512\n",
            "712/712 [==============================] - 0s 35us/sample - loss: 0.5481 - accuracy: 0.7261 - val_loss: 0.4849 - val_accuracy: 0.7989\n",
            "Epoch 190/512\n",
            "712/712 [==============================] - 0s 42us/sample - loss: 0.5519 - accuracy: 0.7331 - val_loss: 0.4808 - val_accuracy: 0.7933\n",
            "Epoch 191/512\n",
            "712/712 [==============================] - 0s 38us/sample - loss: 0.5843 - accuracy: 0.7163 - val_loss: 0.4705 - val_accuracy: 0.7821\n",
            "Epoch 192/512\n",
            "712/712 [==============================] - 0s 38us/sample - loss: 0.5644 - accuracy: 0.7374 - val_loss: 0.5569 - val_accuracy: 0.7430\n",
            "Epoch 193/512\n",
            "712/712 [==============================] - 0s 53us/sample - loss: 0.5498 - accuracy: 0.7388 - val_loss: 0.5121 - val_accuracy: 0.7877\n",
            "Epoch 194/512\n",
            "712/712 [==============================] - 0s 38us/sample - loss: 0.5441 - accuracy: 0.7388 - val_loss: 0.4747 - val_accuracy: 0.8101\n",
            "Epoch 195/512\n",
            "712/712 [==============================] - 0s 36us/sample - loss: 0.5499 - accuracy: 0.7331 - val_loss: 0.5053 - val_accuracy: 0.7821\n",
            "Epoch 196/512\n",
            "712/712 [==============================] - 0s 36us/sample - loss: 0.5410 - accuracy: 0.7360 - val_loss: 0.4678 - val_accuracy: 0.8212\n",
            "Epoch 197/512\n",
            "712/712 [==============================] - 0s 38us/sample - loss: 0.5567 - accuracy: 0.7402 - val_loss: 0.4622 - val_accuracy: 0.7989\n",
            "Epoch 198/512\n",
            "712/712 [==============================] - 0s 42us/sample - loss: 0.5582 - accuracy: 0.7346 - val_loss: 0.4694 - val_accuracy: 0.8156\n",
            "Epoch 199/512\n",
            "712/712 [==============================] - 0s 44us/sample - loss: 0.5457 - accuracy: 0.7528 - val_loss: 0.4489 - val_accuracy: 0.7933\n",
            "Epoch 200/512\n",
            "712/712 [==============================] - 0s 38us/sample - loss: 0.5529 - accuracy: 0.7261 - val_loss: 0.4510 - val_accuracy: 0.7933\n",
            "Epoch 201/512\n",
            "712/712 [==============================] - 0s 38us/sample - loss: 0.5223 - accuracy: 0.7402 - val_loss: 0.4484 - val_accuracy: 0.7877\n",
            "Epoch 202/512\n",
            "712/712 [==============================] - 0s 37us/sample - loss: 0.5296 - accuracy: 0.7444 - val_loss: 0.4512 - val_accuracy: 0.7933\n",
            "Epoch 203/512\n",
            "712/712 [==============================] - 0s 37us/sample - loss: 0.5448 - accuracy: 0.7430 - val_loss: 0.5768 - val_accuracy: 0.7374\n",
            "Epoch 204/512\n",
            "712/712 [==============================] - 0s 40us/sample - loss: 0.5629 - accuracy: 0.7416 - val_loss: 0.5376 - val_accuracy: 0.7486\n",
            "Epoch 205/512\n",
            "712/712 [==============================] - 0s 45us/sample - loss: 0.5232 - accuracy: 0.7640 - val_loss: 0.4653 - val_accuracy: 0.8324\n",
            "Epoch 206/512\n",
            "712/712 [==============================] - 0s 40us/sample - loss: 0.5360 - accuracy: 0.7556 - val_loss: 0.4666 - val_accuracy: 0.8212\n",
            "Epoch 207/512\n",
            "712/712 [==============================] - 0s 41us/sample - loss: 0.5321 - accuracy: 0.7626 - val_loss: 0.4533 - val_accuracy: 0.8268\n",
            "Epoch 208/512\n",
            "712/712 [==============================] - 0s 37us/sample - loss: 0.5270 - accuracy: 0.7500 - val_loss: 0.5068 - val_accuracy: 0.7877\n",
            "Epoch 209/512\n",
            "712/712 [==============================] - 0s 38us/sample - loss: 0.5285 - accuracy: 0.7486 - val_loss: 0.4713 - val_accuracy: 0.8268\n",
            "Epoch 210/512\n",
            "712/712 [==============================] - 0s 36us/sample - loss: 0.5309 - accuracy: 0.7556 - val_loss: 0.4439 - val_accuracy: 0.8101\n",
            "Epoch 211/512\n",
            "712/712 [==============================] - 0s 38us/sample - loss: 0.5315 - accuracy: 0.7640 - val_loss: 0.4499 - val_accuracy: 0.8101\n",
            "Epoch 212/512\n",
            "712/712 [==============================] - 0s 40us/sample - loss: 0.5347 - accuracy: 0.7486 - val_loss: 0.4782 - val_accuracy: 0.8268\n",
            "Epoch 213/512\n",
            "712/712 [==============================] - 0s 38us/sample - loss: 0.5246 - accuracy: 0.7556 - val_loss: 0.5529 - val_accuracy: 0.7709\n",
            "Epoch 214/512\n",
            "712/712 [==============================] - 0s 45us/sample - loss: 0.5362 - accuracy: 0.7486 - val_loss: 0.4853 - val_accuracy: 0.7989\n",
            "Epoch 215/512\n",
            "712/712 [==============================] - 0s 45us/sample - loss: 0.5150 - accuracy: 0.7823 - val_loss: 0.5627 - val_accuracy: 0.7374\n",
            "Epoch 216/512\n",
            "712/712 [==============================] - 0s 46us/sample - loss: 0.5303 - accuracy: 0.7542 - val_loss: 0.5237 - val_accuracy: 0.7654\n",
            "Epoch 217/512\n",
            "712/712 [==============================] - 0s 36us/sample - loss: 0.5316 - accuracy: 0.7626 - val_loss: 0.5375 - val_accuracy: 0.7542\n",
            "Epoch 218/512\n",
            "712/712 [==============================] - 0s 36us/sample - loss: 0.5347 - accuracy: 0.7598 - val_loss: 0.4657 - val_accuracy: 0.8212\n",
            "Epoch 219/512\n",
            "712/712 [==============================] - 0s 38us/sample - loss: 0.5278 - accuracy: 0.7500 - val_loss: 0.4774 - val_accuracy: 0.8212\n",
            "Epoch 220/512\n",
            "712/712 [==============================] - 0s 36us/sample - loss: 0.5467 - accuracy: 0.7317 - val_loss: 0.5431 - val_accuracy: 0.7430\n",
            "Epoch 221/512\n",
            "712/712 [==============================] - 0s 37us/sample - loss: 0.5510 - accuracy: 0.7514 - val_loss: 0.6007 - val_accuracy: 0.7095\n",
            "Epoch 222/512\n",
            "712/712 [==============================] - 0s 40us/sample - loss: 0.5321 - accuracy: 0.7669 - val_loss: 0.4829 - val_accuracy: 0.8045\n",
            "Epoch 223/512\n",
            "712/712 [==============================] - 0s 47us/sample - loss: 0.5255 - accuracy: 0.7598 - val_loss: 0.4637 - val_accuracy: 0.8268\n",
            "Epoch 224/512\n",
            "712/712 [==============================] - 0s 40us/sample - loss: 0.5104 - accuracy: 0.7823 - val_loss: 0.5222 - val_accuracy: 0.7542\n",
            "Epoch 225/512\n",
            "712/712 [==============================] - 0s 38us/sample - loss: 0.5143 - accuracy: 0.7626 - val_loss: 0.5958 - val_accuracy: 0.7318\n",
            "Epoch 226/512\n",
            "712/712 [==============================] - 0s 37us/sample - loss: 0.5271 - accuracy: 0.7528 - val_loss: 0.5048 - val_accuracy: 0.7765\n",
            "Epoch 227/512\n",
            "712/712 [==============================] - 0s 39us/sample - loss: 0.5230 - accuracy: 0.7640 - val_loss: 0.5480 - val_accuracy: 0.7765\n",
            "Epoch 228/512\n",
            "712/712 [==============================] - 0s 37us/sample - loss: 0.5098 - accuracy: 0.7640 - val_loss: 0.5546 - val_accuracy: 0.7542\n",
            "Epoch 229/512\n",
            "712/712 [==============================] - 0s 37us/sample - loss: 0.5130 - accuracy: 0.7683 - val_loss: 0.5228 - val_accuracy: 0.7654\n",
            "Epoch 230/512\n",
            "712/712 [==============================] - 0s 36us/sample - loss: 0.5338 - accuracy: 0.7528 - val_loss: 0.4868 - val_accuracy: 0.8101\n",
            "Epoch 231/512\n",
            "712/712 [==============================] - 0s 42us/sample - loss: 0.5182 - accuracy: 0.7823 - val_loss: 0.4452 - val_accuracy: 0.8268\n",
            "Epoch 232/512\n",
            "712/712 [==============================] - 0s 38us/sample - loss: 0.4977 - accuracy: 0.7935 - val_loss: 0.4380 - val_accuracy: 0.8436\n",
            "Epoch 233/512\n",
            "712/712 [==============================] - 0s 36us/sample - loss: 0.5016 - accuracy: 0.7626 - val_loss: 0.4645 - val_accuracy: 0.8156\n",
            "Epoch 234/512\n",
            "712/712 [==============================] - 0s 37us/sample - loss: 0.5275 - accuracy: 0.7598 - val_loss: 0.4807 - val_accuracy: 0.8101\n",
            "Epoch 235/512\n",
            "712/712 [==============================] - 0s 37us/sample - loss: 0.5093 - accuracy: 0.7725 - val_loss: 0.4794 - val_accuracy: 0.8268\n",
            "Epoch 236/512\n",
            "712/712 [==============================] - 0s 39us/sample - loss: 0.5008 - accuracy: 0.7879 - val_loss: 0.4916 - val_accuracy: 0.7989\n",
            "Epoch 237/512\n",
            "712/712 [==============================] - 0s 42us/sample - loss: 0.4788 - accuracy: 0.7978 - val_loss: 0.4854 - val_accuracy: 0.8045\n",
            "Epoch 238/512\n",
            "712/712 [==============================] - 0s 40us/sample - loss: 0.5183 - accuracy: 0.7612 - val_loss: 0.5120 - val_accuracy: 0.7821\n",
            "Epoch 239/512\n",
            "712/712 [==============================] - 0s 41us/sample - loss: 0.5174 - accuracy: 0.7556 - val_loss: 0.5419 - val_accuracy: 0.7542\n",
            "Epoch 240/512\n",
            "712/712 [==============================] - 0s 40us/sample - loss: 0.5197 - accuracy: 0.7683 - val_loss: 0.5231 - val_accuracy: 0.7765\n",
            "Epoch 241/512\n",
            "712/712 [==============================] - 0s 39us/sample - loss: 0.5253 - accuracy: 0.7584 - val_loss: 0.4520 - val_accuracy: 0.8212\n",
            "Epoch 242/512\n",
            "712/712 [==============================] - 0s 38us/sample - loss: 0.5199 - accuracy: 0.7795 - val_loss: 0.5400 - val_accuracy: 0.7430\n",
            "Epoch 243/512\n",
            "712/712 [==============================] - 0s 34us/sample - loss: 0.5220 - accuracy: 0.7739 - val_loss: 0.4743 - val_accuracy: 0.8156\n",
            "Epoch 244/512\n",
            "712/712 [==============================] - 0s 38us/sample - loss: 0.5124 - accuracy: 0.7753 - val_loss: 0.4576 - val_accuracy: 0.8268\n",
            "Epoch 245/512\n",
            "712/712 [==============================] - 0s 34us/sample - loss: 0.5236 - accuracy: 0.7570 - val_loss: 0.5103 - val_accuracy: 0.7821\n",
            "Epoch 246/512\n",
            "712/712 [==============================] - 0s 32us/sample - loss: 0.4968 - accuracy: 0.7879 - val_loss: 0.5454 - val_accuracy: 0.7598\n",
            "Epoch 247/512\n",
            "712/712 [==============================] - 0s 44us/sample - loss: 0.5110 - accuracy: 0.7725 - val_loss: 0.4304 - val_accuracy: 0.8156\n",
            "Epoch 248/512\n",
            "712/712 [==============================] - 0s 36us/sample - loss: 0.5227 - accuracy: 0.7570 - val_loss: 0.4259 - val_accuracy: 0.8268\n",
            "Epoch 249/512\n",
            "712/712 [==============================] - 0s 39us/sample - loss: 0.5159 - accuracy: 0.7669 - val_loss: 0.4307 - val_accuracy: 0.8268\n",
            "Epoch 250/512\n",
            "712/712 [==============================] - 0s 43us/sample - loss: 0.4810 - accuracy: 0.7823 - val_loss: 0.5239 - val_accuracy: 0.7486\n",
            "Epoch 251/512\n",
            "712/712 [==============================] - 0s 33us/sample - loss: 0.5028 - accuracy: 0.7907 - val_loss: 0.5156 - val_accuracy: 0.7654\n",
            "Epoch 252/512\n",
            "712/712 [==============================] - 0s 33us/sample - loss: 0.5080 - accuracy: 0.7683 - val_loss: 0.4648 - val_accuracy: 0.8156\n",
            "Epoch 253/512\n",
            "712/712 [==============================] - 0s 33us/sample - loss: 0.4836 - accuracy: 0.7739 - val_loss: 0.4682 - val_accuracy: 0.8156\n",
            "Epoch 254/512\n",
            "712/712 [==============================] - 0s 41us/sample - loss: 0.4846 - accuracy: 0.7753 - val_loss: 0.4521 - val_accuracy: 0.8045\n",
            "Epoch 255/512\n",
            "712/712 [==============================] - 0s 38us/sample - loss: 0.5129 - accuracy: 0.7809 - val_loss: 0.4802 - val_accuracy: 0.7989\n",
            "Epoch 256/512\n",
            "712/712 [==============================] - 0s 36us/sample - loss: 0.4821 - accuracy: 0.7809 - val_loss: 0.4594 - val_accuracy: 0.8156\n",
            "Epoch 257/512\n",
            "712/712 [==============================] - 0s 37us/sample - loss: 0.4828 - accuracy: 0.7963 - val_loss: 0.5075 - val_accuracy: 0.7709\n",
            "Epoch 258/512\n",
            "712/712 [==============================] - 0s 40us/sample - loss: 0.4726 - accuracy: 0.8020 - val_loss: 0.4615 - val_accuracy: 0.8212\n",
            "Epoch 259/512\n",
            "712/712 [==============================] - 0s 41us/sample - loss: 0.4767 - accuracy: 0.7921 - val_loss: 0.4741 - val_accuracy: 0.7989\n",
            "Epoch 260/512\n",
            "712/712 [==============================] - 0s 35us/sample - loss: 0.4998 - accuracy: 0.7725 - val_loss: 0.4482 - val_accuracy: 0.8324\n",
            "Epoch 261/512\n",
            "712/712 [==============================] - 0s 39us/sample - loss: 0.4781 - accuracy: 0.7949 - val_loss: 0.4549 - val_accuracy: 0.8212\n",
            "Epoch 262/512\n",
            "712/712 [==============================] - 0s 37us/sample - loss: 0.4847 - accuracy: 0.7907 - val_loss: 0.4267 - val_accuracy: 0.8268\n",
            "Epoch 263/512\n",
            "712/712 [==============================] - 0s 50us/sample - loss: 0.5003 - accuracy: 0.7823 - val_loss: 0.4242 - val_accuracy: 0.8212\n",
            "Epoch 264/512\n",
            "712/712 [==============================] - 0s 48us/sample - loss: 0.4935 - accuracy: 0.7739 - val_loss: 0.4132 - val_accuracy: 0.8436\n",
            "Epoch 265/512\n",
            "712/712 [==============================] - 0s 46us/sample - loss: 0.5026 - accuracy: 0.7963 - val_loss: 0.5045 - val_accuracy: 0.7821\n",
            "Epoch 266/512\n",
            "712/712 [==============================] - 0s 42us/sample - loss: 0.4818 - accuracy: 0.7809 - val_loss: 0.4516 - val_accuracy: 0.8268\n",
            "Epoch 267/512\n",
            "712/712 [==============================] - 0s 42us/sample - loss: 0.4742 - accuracy: 0.7963 - val_loss: 0.4106 - val_accuracy: 0.8212\n",
            "Epoch 268/512\n",
            "712/712 [==============================] - 0s 39us/sample - loss: 0.4991 - accuracy: 0.7865 - val_loss: 0.4544 - val_accuracy: 0.8045\n",
            "Epoch 269/512\n",
            "712/712 [==============================] - 0s 44us/sample - loss: 0.4916 - accuracy: 0.7739 - val_loss: 0.5170 - val_accuracy: 0.7542\n",
            "Epoch 270/512\n",
            "712/712 [==============================] - 0s 41us/sample - loss: 0.4884 - accuracy: 0.7837 - val_loss: 0.4322 - val_accuracy: 0.8268\n",
            "Epoch 271/512\n",
            "712/712 [==============================] - 0s 40us/sample - loss: 0.5098 - accuracy: 0.7837 - val_loss: 0.4182 - val_accuracy: 0.8324\n",
            "Epoch 272/512\n",
            "712/712 [==============================] - 0s 37us/sample - loss: 0.4903 - accuracy: 0.7781 - val_loss: 0.4476 - val_accuracy: 0.8212\n",
            "Epoch 273/512\n",
            "712/712 [==============================] - 0s 39us/sample - loss: 0.4993 - accuracy: 0.7626 - val_loss: 0.4837 - val_accuracy: 0.7877\n",
            "Epoch 274/512\n",
            "712/712 [==============================] - 0s 40us/sample - loss: 0.4809 - accuracy: 0.7963 - val_loss: 0.4423 - val_accuracy: 0.8268\n",
            "Epoch 275/512\n",
            "712/712 [==============================] - 0s 39us/sample - loss: 0.4875 - accuracy: 0.7753 - val_loss: 0.4640 - val_accuracy: 0.8212\n",
            "Epoch 276/512\n",
            "712/712 [==============================] - 0s 40us/sample - loss: 0.4777 - accuracy: 0.8090 - val_loss: 0.4639 - val_accuracy: 0.8101\n",
            "Epoch 277/512\n",
            "712/712 [==============================] - 0s 41us/sample - loss: 0.4919 - accuracy: 0.7823 - val_loss: 0.4515 - val_accuracy: 0.8212\n",
            "Epoch 278/512\n",
            "712/712 [==============================] - 0s 42us/sample - loss: 0.4814 - accuracy: 0.7963 - val_loss: 0.4484 - val_accuracy: 0.8212\n",
            "Epoch 279/512\n",
            "712/712 [==============================] - 0s 39us/sample - loss: 0.4979 - accuracy: 0.7907 - val_loss: 0.5182 - val_accuracy: 0.7486\n",
            "Epoch 280/512\n",
            "712/712 [==============================] - 0s 39us/sample - loss: 0.4893 - accuracy: 0.7837 - val_loss: 0.4320 - val_accuracy: 0.8380\n",
            "Epoch 281/512\n",
            "712/712 [==============================] - 0s 39us/sample - loss: 0.4935 - accuracy: 0.7963 - val_loss: 0.4648 - val_accuracy: 0.7877\n",
            "Epoch 282/512\n",
            "712/712 [==============================] - 0s 39us/sample - loss: 0.4561 - accuracy: 0.7978 - val_loss: 0.4256 - val_accuracy: 0.8268\n",
            "Epoch 283/512\n",
            "712/712 [==============================] - 0s 37us/sample - loss: 0.4826 - accuracy: 0.7823 - val_loss: 0.4615 - val_accuracy: 0.8045\n",
            "Epoch 284/512\n",
            "712/712 [==============================] - 0s 40us/sample - loss: 0.4978 - accuracy: 0.7823 - val_loss: 0.4211 - val_accuracy: 0.8380\n",
            "Epoch 285/512\n",
            "712/712 [==============================] - 0s 48us/sample - loss: 0.4882 - accuracy: 0.7809 - val_loss: 0.4022 - val_accuracy: 0.8380\n",
            "Epoch 286/512\n",
            "712/712 [==============================] - 0s 41us/sample - loss: 0.4974 - accuracy: 0.7739 - val_loss: 0.4103 - val_accuracy: 0.8492\n",
            "Epoch 287/512\n",
            "712/712 [==============================] - 0s 37us/sample - loss: 0.4734 - accuracy: 0.7893 - val_loss: 0.4222 - val_accuracy: 0.8436\n",
            "Epoch 288/512\n",
            "712/712 [==============================] - 0s 40us/sample - loss: 0.4937 - accuracy: 0.7907 - val_loss: 0.4197 - val_accuracy: 0.8492\n",
            "Epoch 289/512\n",
            "712/712 [==============================] - 0s 37us/sample - loss: 0.4715 - accuracy: 0.7907 - val_loss: 0.4519 - val_accuracy: 0.8212\n",
            "Epoch 290/512\n",
            "712/712 [==============================] - 0s 36us/sample - loss: 0.4991 - accuracy: 0.7935 - val_loss: 0.4178 - val_accuracy: 0.8380\n",
            "Epoch 291/512\n",
            "712/712 [==============================] - 0s 37us/sample - loss: 0.4831 - accuracy: 0.7893 - val_loss: 0.4401 - val_accuracy: 0.8268\n",
            "Epoch 292/512\n",
            "712/712 [==============================] - 0s 41us/sample - loss: 0.4919 - accuracy: 0.7907 - val_loss: 0.4075 - val_accuracy: 0.8436\n",
            "Epoch 293/512\n",
            "712/712 [==============================] - 0s 46us/sample - loss: 0.4754 - accuracy: 0.7851 - val_loss: 0.4238 - val_accuracy: 0.8492\n",
            "Epoch 294/512\n",
            "712/712 [==============================] - 0s 37us/sample - loss: 0.4868 - accuracy: 0.8020 - val_loss: 0.4345 - val_accuracy: 0.8045\n",
            "Epoch 295/512\n",
            "712/712 [==============================] - 0s 39us/sample - loss: 0.4888 - accuracy: 0.8020 - val_loss: 0.4450 - val_accuracy: 0.8156\n",
            "Epoch 296/512\n",
            "712/712 [==============================] - 0s 38us/sample - loss: 0.4813 - accuracy: 0.7879 - val_loss: 0.4479 - val_accuracy: 0.8212\n",
            "Epoch 297/512\n",
            "712/712 [==============================] - 0s 40us/sample - loss: 0.4710 - accuracy: 0.8034 - val_loss: 0.3997 - val_accuracy: 0.8547\n",
            "Epoch 298/512\n",
            "712/712 [==============================] - 0s 40us/sample - loss: 0.4626 - accuracy: 0.7963 - val_loss: 0.5322 - val_accuracy: 0.7542\n",
            "Epoch 299/512\n",
            "712/712 [==============================] - 0s 43us/sample - loss: 0.4667 - accuracy: 0.7992 - val_loss: 0.5419 - val_accuracy: 0.7263\n",
            "Epoch 300/512\n",
            "712/712 [==============================] - 0s 42us/sample - loss: 0.4925 - accuracy: 0.7935 - val_loss: 0.4731 - val_accuracy: 0.7821\n",
            "Epoch 301/512\n",
            "712/712 [==============================] - 0s 36us/sample - loss: 0.4749 - accuracy: 0.8020 - val_loss: 0.4620 - val_accuracy: 0.8156\n",
            "Epoch 302/512\n",
            "712/712 [==============================] - 0s 34us/sample - loss: 0.4709 - accuracy: 0.7963 - val_loss: 0.4659 - val_accuracy: 0.7877\n",
            "Epoch 303/512\n",
            "712/712 [==============================] - 0s 39us/sample - loss: 0.4783 - accuracy: 0.7837 - val_loss: 0.4243 - val_accuracy: 0.8380\n",
            "Epoch 304/512\n",
            "712/712 [==============================] - 0s 37us/sample - loss: 0.4826 - accuracy: 0.7992 - val_loss: 0.4452 - val_accuracy: 0.8101\n",
            "Epoch 305/512\n",
            "712/712 [==============================] - 0s 39us/sample - loss: 0.4779 - accuracy: 0.7992 - val_loss: 0.5009 - val_accuracy: 0.7821\n",
            "Epoch 306/512\n",
            "712/712 [==============================] - 0s 43us/sample - loss: 0.4881 - accuracy: 0.7879 - val_loss: 0.4594 - val_accuracy: 0.7933\n",
            "Epoch 307/512\n",
            "712/712 [==============================] - 0s 40us/sample - loss: 0.4675 - accuracy: 0.8118 - val_loss: 0.4020 - val_accuracy: 0.8547\n",
            "Epoch 308/512\n",
            "712/712 [==============================] - 0s 41us/sample - loss: 0.4807 - accuracy: 0.7949 - val_loss: 0.3914 - val_accuracy: 0.8436\n",
            "Epoch 309/512\n",
            "712/712 [==============================] - 0s 35us/sample - loss: 0.4515 - accuracy: 0.8034 - val_loss: 0.4219 - val_accuracy: 0.8380\n",
            "Epoch 310/512\n",
            "712/712 [==============================] - 0s 39us/sample - loss: 0.4843 - accuracy: 0.8020 - val_loss: 0.4194 - val_accuracy: 0.8436\n",
            "Epoch 311/512\n",
            "712/712 [==============================] - 0s 35us/sample - loss: 0.4760 - accuracy: 0.7992 - val_loss: 0.4370 - val_accuracy: 0.8101\n",
            "Epoch 312/512\n",
            "712/712 [==============================] - 0s 43us/sample - loss: 0.4860 - accuracy: 0.7893 - val_loss: 0.4106 - val_accuracy: 0.8492\n",
            "Epoch 313/512\n",
            "712/712 [==============================] - 0s 45us/sample - loss: 0.4559 - accuracy: 0.8062 - val_loss: 0.3977 - val_accuracy: 0.8492\n",
            "Epoch 314/512\n",
            "712/712 [==============================] - 0s 46us/sample - loss: 0.4677 - accuracy: 0.8048 - val_loss: 0.3899 - val_accuracy: 0.8603\n",
            "Epoch 315/512\n",
            "712/712 [==============================] - 0s 40us/sample - loss: 0.4788 - accuracy: 0.8076 - val_loss: 0.3979 - val_accuracy: 0.8547\n",
            "Epoch 316/512\n",
            "712/712 [==============================] - 0s 39us/sample - loss: 0.4773 - accuracy: 0.7978 - val_loss: 0.4061 - val_accuracy: 0.8436\n",
            "Epoch 317/512\n",
            "712/712 [==============================] - 0s 36us/sample - loss: 0.4715 - accuracy: 0.7949 - val_loss: 0.4123 - val_accuracy: 0.8436\n",
            "Epoch 318/512\n",
            "712/712 [==============================] - 0s 39us/sample - loss: 0.4709 - accuracy: 0.8146 - val_loss: 0.4517 - val_accuracy: 0.8045\n",
            "Epoch 319/512\n",
            "712/712 [==============================] - 0s 39us/sample - loss: 0.4671 - accuracy: 0.8034 - val_loss: 0.4228 - val_accuracy: 0.8380\n",
            "Epoch 320/512\n",
            "712/712 [==============================] - 0s 41us/sample - loss: 0.4897 - accuracy: 0.7978 - val_loss: 0.4209 - val_accuracy: 0.8380\n",
            "Epoch 321/512\n",
            "712/712 [==============================] - 0s 39us/sample - loss: 0.4750 - accuracy: 0.8020 - val_loss: 0.4503 - val_accuracy: 0.8045\n",
            "Epoch 322/512\n",
            "712/712 [==============================] - 0s 42us/sample - loss: 0.4809 - accuracy: 0.7949 - val_loss: 0.3898 - val_accuracy: 0.8547\n",
            "Epoch 323/512\n",
            "712/712 [==============================] - 0s 35us/sample - loss: 0.4826 - accuracy: 0.8034 - val_loss: 0.3847 - val_accuracy: 0.8492\n",
            "Epoch 324/512\n",
            "712/712 [==============================] - 0s 47us/sample - loss: 0.4679 - accuracy: 0.8090 - val_loss: 0.4286 - val_accuracy: 0.8212\n",
            "Epoch 325/512\n",
            "712/712 [==============================] - 0s 43us/sample - loss: 0.4657 - accuracy: 0.8034 - val_loss: 0.3976 - val_accuracy: 0.8547\n",
            "Epoch 326/512\n",
            "712/712 [==============================] - 0s 39us/sample - loss: 0.4636 - accuracy: 0.8216 - val_loss: 0.3897 - val_accuracy: 0.8547\n",
            "Epoch 327/512\n",
            "712/712 [==============================] - 0s 37us/sample - loss: 0.4819 - accuracy: 0.7992 - val_loss: 0.4180 - val_accuracy: 0.8436\n",
            "Epoch 328/512\n",
            "712/712 [==============================] - 0s 35us/sample - loss: 0.4837 - accuracy: 0.7893 - val_loss: 0.4026 - val_accuracy: 0.8492\n",
            "Epoch 329/512\n",
            "712/712 [==============================] - 0s 41us/sample - loss: 0.4593 - accuracy: 0.8146 - val_loss: 0.4045 - val_accuracy: 0.8436\n",
            "Epoch 330/512\n",
            "712/712 [==============================] - 0s 40us/sample - loss: 0.4710 - accuracy: 0.8020 - val_loss: 0.3893 - val_accuracy: 0.8659\n",
            "Epoch 331/512\n",
            "712/712 [==============================] - 0s 39us/sample - loss: 0.4469 - accuracy: 0.8034 - val_loss: 0.4236 - val_accuracy: 0.8380\n",
            "Epoch 332/512\n",
            "712/712 [==============================] - 0s 38us/sample - loss: 0.4757 - accuracy: 0.7978 - val_loss: 0.4274 - val_accuracy: 0.8380\n",
            "Epoch 333/512\n",
            "712/712 [==============================] - 0s 41us/sample - loss: 0.4681 - accuracy: 0.8132 - val_loss: 0.4058 - val_accuracy: 0.8436\n",
            "Epoch 334/512\n",
            "712/712 [==============================] - 0s 39us/sample - loss: 0.4651 - accuracy: 0.8020 - val_loss: 0.3983 - val_accuracy: 0.8547\n",
            "Epoch 335/512\n",
            "712/712 [==============================] - 0s 39us/sample - loss: 0.4797 - accuracy: 0.8034 - val_loss: 0.4318 - val_accuracy: 0.8268\n",
            "Epoch 336/512\n",
            "712/712 [==============================] - 0s 43us/sample - loss: 0.4824 - accuracy: 0.7907 - val_loss: 0.3906 - val_accuracy: 0.8547\n",
            "Epoch 337/512\n",
            "712/712 [==============================] - 0s 42us/sample - loss: 0.4766 - accuracy: 0.8006 - val_loss: 0.3823 - val_accuracy: 0.8492\n",
            "Epoch 338/512\n",
            "712/712 [==============================] - 0s 38us/sample - loss: 0.4805 - accuracy: 0.7879 - val_loss: 0.3983 - val_accuracy: 0.8436\n",
            "Epoch 339/512\n",
            "712/712 [==============================] - 0s 34us/sample - loss: 0.4695 - accuracy: 0.7992 - val_loss: 0.4235 - val_accuracy: 0.8268\n",
            "Epoch 340/512\n",
            "712/712 [==============================] - 0s 36us/sample - loss: 0.4581 - accuracy: 0.8104 - val_loss: 0.4198 - val_accuracy: 0.8324\n",
            "Epoch 341/512\n",
            "712/712 [==============================] - 0s 43us/sample - loss: 0.4542 - accuracy: 0.8174 - val_loss: 0.4125 - val_accuracy: 0.8436\n",
            "Epoch 342/512\n",
            "712/712 [==============================] - 0s 40us/sample - loss: 0.4678 - accuracy: 0.7992 - val_loss: 0.3785 - val_accuracy: 0.8324\n",
            "Epoch 343/512\n",
            "712/712 [==============================] - 0s 42us/sample - loss: 0.4556 - accuracy: 0.8104 - val_loss: 0.3884 - val_accuracy: 0.8547\n",
            "Epoch 344/512\n",
            "712/712 [==============================] - 0s 40us/sample - loss: 0.4654 - accuracy: 0.8146 - val_loss: 0.3828 - val_accuracy: 0.8603\n",
            "Epoch 345/512\n",
            "712/712 [==============================] - 0s 38us/sample - loss: 0.4634 - accuracy: 0.8146 - val_loss: 0.3803 - val_accuracy: 0.8492\n",
            "Epoch 346/512\n",
            "712/712 [==============================] - 0s 41us/sample - loss: 0.4743 - accuracy: 0.8132 - val_loss: 0.3989 - val_accuracy: 0.8380\n",
            "Epoch 347/512\n",
            "712/712 [==============================] - 0s 45us/sample - loss: 0.4581 - accuracy: 0.8006 - val_loss: 0.3865 - val_accuracy: 0.8547\n",
            "Epoch 348/512\n",
            "712/712 [==============================] - 0s 37us/sample - loss: 0.4516 - accuracy: 0.8132 - val_loss: 0.3840 - val_accuracy: 0.8492\n",
            "Epoch 349/512\n",
            "712/712 [==============================] - 0s 37us/sample - loss: 0.4684 - accuracy: 0.8146 - val_loss: 0.3775 - val_accuracy: 0.8603\n",
            "Epoch 350/512\n",
            "712/712 [==============================] - 0s 41us/sample - loss: 0.4468 - accuracy: 0.8146 - val_loss: 0.4057 - val_accuracy: 0.8380\n",
            "Epoch 351/512\n",
            "712/712 [==============================] - 0s 38us/sample - loss: 0.4477 - accuracy: 0.8188 - val_loss: 0.3860 - val_accuracy: 0.8492\n",
            "Epoch 352/512\n",
            "712/712 [==============================] - 0s 40us/sample - loss: 0.4554 - accuracy: 0.8020 - val_loss: 0.3859 - val_accuracy: 0.8492\n",
            "Epoch 353/512\n",
            "712/712 [==============================] - 0s 37us/sample - loss: 0.4592 - accuracy: 0.8076 - val_loss: 0.4034 - val_accuracy: 0.8380\n",
            "Epoch 354/512\n",
            "712/712 [==============================] - 0s 42us/sample - loss: 0.4437 - accuracy: 0.8188 - val_loss: 0.4043 - val_accuracy: 0.8380\n",
            "Epoch 355/512\n",
            "712/712 [==============================] - 0s 41us/sample - loss: 0.4626 - accuracy: 0.8132 - val_loss: 0.3969 - val_accuracy: 0.8380\n",
            "Epoch 356/512\n",
            "712/712 [==============================] - 0s 34us/sample - loss: 0.4577 - accuracy: 0.8048 - val_loss: 0.3905 - val_accuracy: 0.8492\n",
            "Epoch 357/512\n",
            "712/712 [==============================] - 0s 43us/sample - loss: 0.4550 - accuracy: 0.8104 - val_loss: 0.3889 - val_accuracy: 0.8436\n",
            "Epoch 358/512\n",
            "712/712 [==============================] - 0s 36us/sample - loss: 0.4450 - accuracy: 0.8160 - val_loss: 0.4011 - val_accuracy: 0.8436\n",
            "Epoch 359/512\n",
            "712/712 [==============================] - 0s 37us/sample - loss: 0.4451 - accuracy: 0.8076 - val_loss: 0.3924 - val_accuracy: 0.8547\n",
            "Epoch 360/512\n",
            "712/712 [==============================] - 0s 34us/sample - loss: 0.4517 - accuracy: 0.8104 - val_loss: 0.3908 - val_accuracy: 0.8547\n",
            "Epoch 361/512\n",
            "712/712 [==============================] - 0s 42us/sample - loss: 0.4545 - accuracy: 0.8202 - val_loss: 0.4181 - val_accuracy: 0.8156\n",
            "Epoch 362/512\n",
            "712/712 [==============================] - 0s 44us/sample - loss: 0.4681 - accuracy: 0.7992 - val_loss: 0.3998 - val_accuracy: 0.8492\n",
            "Epoch 363/512\n",
            "712/712 [==============================] - 0s 39us/sample - loss: 0.4483 - accuracy: 0.8301 - val_loss: 0.4208 - val_accuracy: 0.8324\n",
            "Epoch 364/512\n",
            "712/712 [==============================] - 0s 42us/sample - loss: 0.4655 - accuracy: 0.8104 - val_loss: 0.4012 - val_accuracy: 0.8380\n",
            "Epoch 365/512\n",
            "712/712 [==============================] - 0s 41us/sample - loss: 0.4514 - accuracy: 0.8132 - val_loss: 0.3918 - val_accuracy: 0.8547\n",
            "Epoch 366/512\n",
            "712/712 [==============================] - 0s 40us/sample - loss: 0.4468 - accuracy: 0.8132 - val_loss: 0.3848 - val_accuracy: 0.8659\n",
            "Epoch 367/512\n",
            "712/712 [==============================] - 0s 41us/sample - loss: 0.4417 - accuracy: 0.8146 - val_loss: 0.3830 - val_accuracy: 0.8603\n",
            "Epoch 368/512\n",
            "712/712 [==============================] - 0s 42us/sample - loss: 0.4584 - accuracy: 0.8174 - val_loss: 0.3960 - val_accuracy: 0.8547\n",
            "Epoch 369/512\n",
            "712/712 [==============================] - 0s 46us/sample - loss: 0.4729 - accuracy: 0.8146 - val_loss: 0.4254 - val_accuracy: 0.8101\n",
            "Epoch 370/512\n",
            "712/712 [==============================] - 0s 48us/sample - loss: 0.4601 - accuracy: 0.8034 - val_loss: 0.3968 - val_accuracy: 0.8324\n",
            "Epoch 371/512\n",
            "712/712 [==============================] - 0s 47us/sample - loss: 0.4468 - accuracy: 0.8076 - val_loss: 0.3897 - val_accuracy: 0.8436\n",
            "Epoch 372/512\n",
            "712/712 [==============================] - 0s 42us/sample - loss: 0.4583 - accuracy: 0.8104 - val_loss: 0.3838 - val_accuracy: 0.8547\n",
            "Epoch 373/512\n",
            "712/712 [==============================] - 0s 40us/sample - loss: 0.4503 - accuracy: 0.8118 - val_loss: 0.3866 - val_accuracy: 0.8547\n",
            "Epoch 374/512\n",
            "712/712 [==============================] - 0s 44us/sample - loss: 0.4565 - accuracy: 0.8034 - val_loss: 0.3883 - val_accuracy: 0.8324\n",
            "Epoch 375/512\n",
            "712/712 [==============================] - 0s 40us/sample - loss: 0.4488 - accuracy: 0.8062 - val_loss: 0.3741 - val_accuracy: 0.8492\n",
            "Epoch 376/512\n",
            "712/712 [==============================] - 0s 41us/sample - loss: 0.4484 - accuracy: 0.8216 - val_loss: 0.3993 - val_accuracy: 0.8380\n",
            "Epoch 377/512\n",
            "712/712 [==============================] - 0s 46us/sample - loss: 0.4425 - accuracy: 0.8188 - val_loss: 0.3814 - val_accuracy: 0.8324\n",
            "Epoch 378/512\n",
            "712/712 [==============================] - 0s 42us/sample - loss: 0.4674 - accuracy: 0.8006 - val_loss: 0.3753 - val_accuracy: 0.8603\n",
            "Epoch 379/512\n",
            "712/712 [==============================] - 0s 42us/sample - loss: 0.4588 - accuracy: 0.8160 - val_loss: 0.3763 - val_accuracy: 0.8603\n",
            "Epoch 380/512\n",
            "712/712 [==============================] - 0s 40us/sample - loss: 0.4495 - accuracy: 0.8090 - val_loss: 0.3883 - val_accuracy: 0.8492\n",
            "Epoch 381/512\n",
            "712/712 [==============================] - 0s 42us/sample - loss: 0.4416 - accuracy: 0.8146 - val_loss: 0.3842 - val_accuracy: 0.8492\n",
            "Epoch 382/512\n",
            "712/712 [==============================] - 0s 38us/sample - loss: 0.4485 - accuracy: 0.8104 - val_loss: 0.3903 - val_accuracy: 0.8492\n",
            "Epoch 383/512\n",
            "712/712 [==============================] - 0s 38us/sample - loss: 0.4579 - accuracy: 0.8006 - val_loss: 0.3700 - val_accuracy: 0.8547\n",
            "Epoch 384/512\n",
            "712/712 [==============================] - 0s 38us/sample - loss: 0.4467 - accuracy: 0.8104 - val_loss: 0.3761 - val_accuracy: 0.8492\n",
            "Epoch 385/512\n",
            "712/712 [==============================] - 0s 35us/sample - loss: 0.4297 - accuracy: 0.8258 - val_loss: 0.3969 - val_accuracy: 0.8380\n",
            "Epoch 386/512\n",
            "712/712 [==============================] - 0s 37us/sample - loss: 0.4530 - accuracy: 0.8034 - val_loss: 0.3944 - val_accuracy: 0.8380\n",
            "Epoch 387/512\n",
            "712/712 [==============================] - 0s 43us/sample - loss: 0.4628 - accuracy: 0.8132 - val_loss: 0.3793 - val_accuracy: 0.8492\n",
            "Epoch 388/512\n",
            "712/712 [==============================] - 0s 40us/sample - loss: 0.4326 - accuracy: 0.8258 - val_loss: 0.4186 - val_accuracy: 0.8324\n",
            "Epoch 389/512\n",
            "712/712 [==============================] - 0s 43us/sample - loss: 0.4525 - accuracy: 0.8146 - val_loss: 0.4503 - val_accuracy: 0.8101\n",
            "Epoch 390/512\n",
            "712/712 [==============================] - 0s 36us/sample - loss: 0.4473 - accuracy: 0.8090 - val_loss: 0.4110 - val_accuracy: 0.8324\n",
            "Epoch 391/512\n",
            "712/712 [==============================] - 0s 39us/sample - loss: 0.4390 - accuracy: 0.8230 - val_loss: 0.3801 - val_accuracy: 0.8492\n",
            "Epoch 392/512\n",
            "712/712 [==============================] - 0s 39us/sample - loss: 0.4472 - accuracy: 0.8132 - val_loss: 0.4090 - val_accuracy: 0.8380\n",
            "Epoch 393/512\n",
            "712/712 [==============================] - 0s 38us/sample - loss: 0.4603 - accuracy: 0.8146 - val_loss: 0.3878 - val_accuracy: 0.8492\n",
            "Epoch 394/512\n",
            "712/712 [==============================] - 0s 40us/sample - loss: 0.4585 - accuracy: 0.8146 - val_loss: 0.4254 - val_accuracy: 0.8156\n",
            "Epoch 395/512\n",
            "712/712 [==============================] - 0s 39us/sample - loss: 0.4508 - accuracy: 0.8258 - val_loss: 0.3931 - val_accuracy: 0.8492\n",
            "Epoch 396/512\n",
            "712/712 [==============================] - 0s 42us/sample - loss: 0.4487 - accuracy: 0.8146 - val_loss: 0.3763 - val_accuracy: 0.8547\n",
            "Epoch 397/512\n",
            "712/712 [==============================] - 0s 42us/sample - loss: 0.4585 - accuracy: 0.8006 - val_loss: 0.3890 - val_accuracy: 0.8492\n",
            "Epoch 398/512\n",
            "712/712 [==============================] - 0s 35us/sample - loss: 0.4511 - accuracy: 0.8174 - val_loss: 0.4312 - val_accuracy: 0.8101\n",
            "Epoch 399/512\n",
            "712/712 [==============================] - 0s 39us/sample - loss: 0.4544 - accuracy: 0.7978 - val_loss: 0.4014 - val_accuracy: 0.8324\n",
            "Epoch 400/512\n",
            "712/712 [==============================] - 0s 43us/sample - loss: 0.4357 - accuracy: 0.8160 - val_loss: 0.4020 - val_accuracy: 0.8156\n",
            "Epoch 401/512\n",
            "712/712 [==============================] - 0s 39us/sample - loss: 0.4484 - accuracy: 0.8146 - val_loss: 0.3677 - val_accuracy: 0.8436\n",
            "Epoch 402/512\n",
            "712/712 [==============================] - 0s 42us/sample - loss: 0.4560 - accuracy: 0.7949 - val_loss: 0.3712 - val_accuracy: 0.8380\n",
            "Epoch 403/512\n",
            "712/712 [==============================] - 0s 44us/sample - loss: 0.4649 - accuracy: 0.8062 - val_loss: 0.3745 - val_accuracy: 0.8547\n",
            "Epoch 404/512\n",
            "712/712 [==============================] - 0s 42us/sample - loss: 0.4428 - accuracy: 0.8132 - val_loss: 0.3843 - val_accuracy: 0.8380\n",
            "Epoch 405/512\n",
            "712/712 [==============================] - 0s 37us/sample - loss: 0.4697 - accuracy: 0.8132 - val_loss: 0.3653 - val_accuracy: 0.8492\n",
            "Epoch 406/512\n",
            "712/712 [==============================] - 0s 40us/sample - loss: 0.4563 - accuracy: 0.8090 - val_loss: 0.3681 - val_accuracy: 0.8547\n",
            "Epoch 407/512\n",
            "712/712 [==============================] - 0s 41us/sample - loss: 0.4466 - accuracy: 0.8076 - val_loss: 0.3806 - val_accuracy: 0.8436\n",
            "Epoch 408/512\n",
            "712/712 [==============================] - 0s 39us/sample - loss: 0.4462 - accuracy: 0.8076 - val_loss: 0.3681 - val_accuracy: 0.8492\n",
            "Epoch 409/512\n",
            "712/712 [==============================] - 0s 38us/sample - loss: 0.4279 - accuracy: 0.8146 - val_loss: 0.3878 - val_accuracy: 0.8436\n",
            "Epoch 410/512\n",
            "712/712 [==============================] - 0s 38us/sample - loss: 0.4558 - accuracy: 0.8174 - val_loss: 0.3799 - val_accuracy: 0.8436\n",
            "Epoch 411/512\n",
            "712/712 [==============================] - 0s 40us/sample - loss: 0.4510 - accuracy: 0.8104 - val_loss: 0.3720 - val_accuracy: 0.8380\n",
            "Epoch 412/512\n",
            "712/712 [==============================] - 0s 37us/sample - loss: 0.4573 - accuracy: 0.8062 - val_loss: 0.3808 - val_accuracy: 0.8380\n",
            "Epoch 413/512\n",
            "712/712 [==============================] - 0s 37us/sample - loss: 0.4501 - accuracy: 0.8132 - val_loss: 0.3972 - val_accuracy: 0.8324\n",
            "Epoch 414/512\n",
            "712/712 [==============================] - 0s 42us/sample - loss: 0.4661 - accuracy: 0.8076 - val_loss: 0.3913 - val_accuracy: 0.8380\n",
            "Epoch 415/512\n",
            "712/712 [==============================] - 0s 39us/sample - loss: 0.4429 - accuracy: 0.8146 - val_loss: 0.3749 - val_accuracy: 0.8436\n",
            "Epoch 416/512\n",
            "712/712 [==============================] - 0s 41us/sample - loss: 0.4622 - accuracy: 0.8062 - val_loss: 0.3840 - val_accuracy: 0.8436\n",
            "Epoch 417/512\n",
            "712/712 [==============================] - 0s 39us/sample - loss: 0.4300 - accuracy: 0.8244 - val_loss: 0.3920 - val_accuracy: 0.8324\n",
            "Epoch 418/512\n",
            "712/712 [==============================] - 0s 34us/sample - loss: 0.4527 - accuracy: 0.8104 - val_loss: 0.3910 - val_accuracy: 0.8380\n",
            "Epoch 419/512\n",
            "712/712 [==============================] - 0s 37us/sample - loss: 0.4286 - accuracy: 0.8315 - val_loss: 0.3913 - val_accuracy: 0.8436\n",
            "Epoch 420/512\n",
            "712/712 [==============================] - 0s 34us/sample - loss: 0.4494 - accuracy: 0.8188 - val_loss: 0.3821 - val_accuracy: 0.8436\n",
            "Epoch 421/512\n",
            "712/712 [==============================] - 0s 39us/sample - loss: 0.4495 - accuracy: 0.8258 - val_loss: 0.3830 - val_accuracy: 0.8436\n",
            "Epoch 422/512\n",
            "712/712 [==============================] - 0s 40us/sample - loss: 0.4404 - accuracy: 0.8244 - val_loss: 0.3707 - val_accuracy: 0.8436\n",
            "Epoch 423/512\n",
            "712/712 [==============================] - 0s 43us/sample - loss: 0.4495 - accuracy: 0.8160 - val_loss: 0.3833 - val_accuracy: 0.8436\n",
            "Epoch 424/512\n",
            "712/712 [==============================] - 0s 32us/sample - loss: 0.4288 - accuracy: 0.8230 - val_loss: 0.3850 - val_accuracy: 0.8268\n",
            "Epoch 425/512\n",
            "712/712 [==============================] - 0s 39us/sample - loss: 0.4368 - accuracy: 0.8301 - val_loss: 0.3691 - val_accuracy: 0.8380\n",
            "Epoch 426/512\n",
            "712/712 [==============================] - 0s 42us/sample - loss: 0.4319 - accuracy: 0.8174 - val_loss: 0.3857 - val_accuracy: 0.8324\n",
            "Epoch 427/512\n",
            "712/712 [==============================] - 0s 40us/sample - loss: 0.4420 - accuracy: 0.8048 - val_loss: 0.3939 - val_accuracy: 0.8324\n",
            "Epoch 428/512\n",
            "712/712 [==============================] - 0s 38us/sample - loss: 0.4390 - accuracy: 0.8202 - val_loss: 0.3806 - val_accuracy: 0.8436\n",
            "Epoch 429/512\n",
            "712/712 [==============================] - 0s 47us/sample - loss: 0.4277 - accuracy: 0.8188 - val_loss: 0.3991 - val_accuracy: 0.8380\n",
            "Epoch 430/512\n",
            "712/712 [==============================] - 0s 43us/sample - loss: 0.4370 - accuracy: 0.8160 - val_loss: 0.3810 - val_accuracy: 0.8492\n",
            "Epoch 431/512\n",
            "712/712 [==============================] - 0s 39us/sample - loss: 0.4425 - accuracy: 0.8216 - val_loss: 0.3778 - val_accuracy: 0.8436\n",
            "Epoch 432/512\n",
            "712/712 [==============================] - 0s 35us/sample - loss: 0.4553 - accuracy: 0.8258 - val_loss: 0.3708 - val_accuracy: 0.8436\n",
            "Epoch 433/512\n",
            "712/712 [==============================] - 0s 39us/sample - loss: 0.4266 - accuracy: 0.8230 - val_loss: 0.3737 - val_accuracy: 0.8492\n",
            "Epoch 434/512\n",
            "712/712 [==============================] - 0s 38us/sample - loss: 0.4301 - accuracy: 0.8301 - val_loss: 0.3790 - val_accuracy: 0.8547\n",
            "Epoch 435/512\n",
            "712/712 [==============================] - 0s 35us/sample - loss: 0.4449 - accuracy: 0.8230 - val_loss: 0.3781 - val_accuracy: 0.8380\n",
            "Epoch 436/512\n",
            "712/712 [==============================] - 0s 47us/sample - loss: 0.4577 - accuracy: 0.8202 - val_loss: 0.3796 - val_accuracy: 0.8492\n",
            "Epoch 437/512\n",
            "712/712 [==============================] - 0s 44us/sample - loss: 0.4428 - accuracy: 0.8174 - val_loss: 0.3825 - val_accuracy: 0.8436\n",
            "Epoch 438/512\n",
            "712/712 [==============================] - 0s 40us/sample - loss: 0.4391 - accuracy: 0.8216 - val_loss: 0.3700 - val_accuracy: 0.8436\n",
            "Epoch 439/512\n",
            "712/712 [==============================] - 0s 37us/sample - loss: 0.4366 - accuracy: 0.8230 - val_loss: 0.3769 - val_accuracy: 0.8492\n",
            "Epoch 440/512\n",
            "712/712 [==============================] - 0s 42us/sample - loss: 0.4294 - accuracy: 0.8287 - val_loss: 0.3670 - val_accuracy: 0.8436\n",
            "Epoch 441/512\n",
            "712/712 [==============================] - 0s 36us/sample - loss: 0.4466 - accuracy: 0.8244 - val_loss: 0.3797 - val_accuracy: 0.8380\n",
            "Epoch 442/512\n",
            "712/712 [==============================] - 0s 37us/sample - loss: 0.4523 - accuracy: 0.8020 - val_loss: 0.3779 - val_accuracy: 0.8380\n",
            "Epoch 443/512\n",
            "712/712 [==============================] - 0s 36us/sample - loss: 0.4439 - accuracy: 0.8146 - val_loss: 0.3800 - val_accuracy: 0.8436\n",
            "Epoch 444/512\n",
            "712/712 [==============================] - 0s 33us/sample - loss: 0.4463 - accuracy: 0.8230 - val_loss: 0.3916 - val_accuracy: 0.8324\n",
            "Epoch 445/512\n",
            "712/712 [==============================] - 0s 35us/sample - loss: 0.4269 - accuracy: 0.8272 - val_loss: 0.3877 - val_accuracy: 0.8380\n",
            "Epoch 446/512\n",
            "712/712 [==============================] - 0s 36us/sample - loss: 0.4430 - accuracy: 0.8104 - val_loss: 0.3698 - val_accuracy: 0.8436\n",
            "Epoch 447/512\n",
            "712/712 [==============================] - 0s 34us/sample - loss: 0.4501 - accuracy: 0.8034 - val_loss: 0.3789 - val_accuracy: 0.8380\n",
            "Epoch 448/512\n",
            "712/712 [==============================] - 0s 44us/sample - loss: 0.4368 - accuracy: 0.8272 - val_loss: 0.3855 - val_accuracy: 0.8380\n",
            "Epoch 449/512\n",
            "712/712 [==============================] - 0s 38us/sample - loss: 0.4298 - accuracy: 0.8160 - val_loss: 0.3806 - val_accuracy: 0.8436\n",
            "Epoch 450/512\n",
            "712/712 [==============================] - 0s 40us/sample - loss: 0.4256 - accuracy: 0.8202 - val_loss: 0.3713 - val_accuracy: 0.8492\n",
            "Epoch 451/512\n",
            "712/712 [==============================] - 0s 35us/sample - loss: 0.4337 - accuracy: 0.8160 - val_loss: 0.3745 - val_accuracy: 0.8436\n",
            "Epoch 452/512\n",
            "712/712 [==============================] - 0s 40us/sample - loss: 0.4608 - accuracy: 0.8020 - val_loss: 0.3737 - val_accuracy: 0.8436\n",
            "Epoch 453/512\n",
            "712/712 [==============================] - 0s 38us/sample - loss: 0.4606 - accuracy: 0.8174 - val_loss: 0.3746 - val_accuracy: 0.8492\n",
            "Epoch 454/512\n",
            "712/712 [==============================] - 0s 37us/sample - loss: 0.4382 - accuracy: 0.8132 - val_loss: 0.3737 - val_accuracy: 0.8380\n",
            "Epoch 455/512\n",
            "712/712 [==============================] - 0s 42us/sample - loss: 0.4319 - accuracy: 0.8287 - val_loss: 0.3773 - val_accuracy: 0.8436\n",
            "Epoch 456/512\n",
            "712/712 [==============================] - 0s 41us/sample - loss: 0.4557 - accuracy: 0.8174 - val_loss: 0.3740 - val_accuracy: 0.8380\n",
            "Epoch 457/512\n",
            "712/712 [==============================] - 0s 41us/sample - loss: 0.4354 - accuracy: 0.8230 - val_loss: 0.3734 - val_accuracy: 0.8380\n",
            "Epoch 458/512\n",
            "712/712 [==============================] - 0s 34us/sample - loss: 0.4318 - accuracy: 0.8244 - val_loss: 0.3752 - val_accuracy: 0.8324\n",
            "Epoch 459/512\n",
            "712/712 [==============================] - 0s 43us/sample - loss: 0.4239 - accuracy: 0.8301 - val_loss: 0.3769 - val_accuracy: 0.8436\n",
            "Epoch 460/512\n",
            "712/712 [==============================] - 0s 37us/sample - loss: 0.4232 - accuracy: 0.8343 - val_loss: 0.3718 - val_accuracy: 0.8547\n",
            "Epoch 461/512\n",
            "712/712 [==============================] - 0s 36us/sample - loss: 0.4318 - accuracy: 0.8287 - val_loss: 0.3800 - val_accuracy: 0.8436\n",
            "Epoch 462/512\n",
            "712/712 [==============================] - 0s 39us/sample - loss: 0.4414 - accuracy: 0.8272 - val_loss: 0.3741 - val_accuracy: 0.8268\n",
            "Epoch 463/512\n",
            "712/712 [==============================] - 0s 38us/sample - loss: 0.4361 - accuracy: 0.8118 - val_loss: 0.3694 - val_accuracy: 0.8380\n",
            "Epoch 464/512\n",
            "712/712 [==============================] - 0s 40us/sample - loss: 0.4414 - accuracy: 0.8104 - val_loss: 0.3711 - val_accuracy: 0.8380\n",
            "Epoch 465/512\n",
            "712/712 [==============================] - 0s 42us/sample - loss: 0.4612 - accuracy: 0.8118 - val_loss: 0.3869 - val_accuracy: 0.8324\n",
            "Epoch 466/512\n",
            "712/712 [==============================] - 0s 39us/sample - loss: 0.4317 - accuracy: 0.8329 - val_loss: 0.3842 - val_accuracy: 0.8380\n",
            "Epoch 467/512\n",
            "712/712 [==============================] - 0s 42us/sample - loss: 0.4542 - accuracy: 0.8188 - val_loss: 0.3834 - val_accuracy: 0.8436\n",
            "Epoch 468/512\n",
            "712/712 [==============================] - 0s 38us/sample - loss: 0.4442 - accuracy: 0.8174 - val_loss: 0.3827 - val_accuracy: 0.8492\n",
            "Epoch 469/512\n",
            "712/712 [==============================] - 0s 39us/sample - loss: 0.4373 - accuracy: 0.8188 - val_loss: 0.3903 - val_accuracy: 0.8436\n",
            "Epoch 470/512\n",
            "712/712 [==============================] - 0s 39us/sample - loss: 0.4284 - accuracy: 0.8244 - val_loss: 0.3862 - val_accuracy: 0.8380\n",
            "Epoch 471/512\n",
            "712/712 [==============================] - 0s 49us/sample - loss: 0.4226 - accuracy: 0.8216 - val_loss: 0.3815 - val_accuracy: 0.8380\n",
            "Epoch 472/512\n",
            "712/712 [==============================] - 0s 37us/sample - loss: 0.4146 - accuracy: 0.8230 - val_loss: 0.3839 - val_accuracy: 0.8380\n",
            "Epoch 473/512\n",
            "712/712 [==============================] - 0s 39us/sample - loss: 0.4529 - accuracy: 0.8090 - val_loss: 0.4017 - val_accuracy: 0.8380\n",
            "Epoch 474/512\n",
            "712/712 [==============================] - 0s 44us/sample - loss: 0.4451 - accuracy: 0.8188 - val_loss: 0.4187 - val_accuracy: 0.8045\n",
            "Epoch 475/512\n",
            "712/712 [==============================] - 0s 36us/sample - loss: 0.4307 - accuracy: 0.8146 - val_loss: 0.3889 - val_accuracy: 0.8380\n",
            "Epoch 476/512\n",
            "712/712 [==============================] - 0s 37us/sample - loss: 0.4374 - accuracy: 0.8034 - val_loss: 0.4037 - val_accuracy: 0.8324\n",
            "Epoch 477/512\n",
            "712/712 [==============================] - 0s 34us/sample - loss: 0.4523 - accuracy: 0.8160 - val_loss: 0.3974 - val_accuracy: 0.8268\n",
            "Epoch 478/512\n",
            "712/712 [==============================] - 0s 36us/sample - loss: 0.3951 - accuracy: 0.8357 - val_loss: 0.4007 - val_accuracy: 0.8268\n",
            "Epoch 479/512\n",
            "712/712 [==============================] - 0s 42us/sample - loss: 0.4231 - accuracy: 0.8301 - val_loss: 0.3954 - val_accuracy: 0.8324\n",
            "Epoch 480/512\n",
            "712/712 [==============================] - 0s 45us/sample - loss: 0.4314 - accuracy: 0.8216 - val_loss: 0.3845 - val_accuracy: 0.8380\n",
            "Epoch 481/512\n",
            "712/712 [==============================] - 0s 44us/sample - loss: 0.4477 - accuracy: 0.8118 - val_loss: 0.3778 - val_accuracy: 0.8380\n",
            "Epoch 482/512\n",
            "712/712 [==============================] - 0s 35us/sample - loss: 0.4256 - accuracy: 0.8118 - val_loss: 0.3681 - val_accuracy: 0.8324\n",
            "Epoch 483/512\n",
            "712/712 [==============================] - 0s 35us/sample - loss: 0.4192 - accuracy: 0.8357 - val_loss: 0.3804 - val_accuracy: 0.8380\n",
            "Epoch 484/512\n",
            "712/712 [==============================] - 0s 36us/sample - loss: 0.4278 - accuracy: 0.8329 - val_loss: 0.3888 - val_accuracy: 0.8380\n",
            "Epoch 485/512\n",
            "712/712 [==============================] - 0s 44us/sample - loss: 0.4405 - accuracy: 0.8244 - val_loss: 0.3760 - val_accuracy: 0.8380\n",
            "Epoch 486/512\n",
            "712/712 [==============================] - 0s 39us/sample - loss: 0.4454 - accuracy: 0.8146 - val_loss: 0.3858 - val_accuracy: 0.8324\n",
            "Epoch 487/512\n",
            "712/712 [==============================] - 0s 35us/sample - loss: 0.4513 - accuracy: 0.8174 - val_loss: 0.3779 - val_accuracy: 0.8324\n",
            "Epoch 488/512\n",
            "712/712 [==============================] - 0s 40us/sample - loss: 0.4328 - accuracy: 0.8230 - val_loss: 0.3814 - val_accuracy: 0.8380\n",
            "Epoch 489/512\n",
            "712/712 [==============================] - 0s 41us/sample - loss: 0.4423 - accuracy: 0.8258 - val_loss: 0.3859 - val_accuracy: 0.8268\n",
            "Epoch 490/512\n",
            "712/712 [==============================] - 0s 40us/sample - loss: 0.4218 - accuracy: 0.8258 - val_loss: 0.3814 - val_accuracy: 0.8268\n",
            "Epoch 491/512\n",
            "712/712 [==============================] - 0s 38us/sample - loss: 0.4310 - accuracy: 0.8272 - val_loss: 0.3801 - val_accuracy: 0.8268\n",
            "Epoch 492/512\n",
            "712/712 [==============================] - 0s 39us/sample - loss: 0.4544 - accuracy: 0.8160 - val_loss: 0.3786 - val_accuracy: 0.8324\n",
            "Epoch 493/512\n",
            "712/712 [==============================] - 0s 40us/sample - loss: 0.4067 - accuracy: 0.8371 - val_loss: 0.3897 - val_accuracy: 0.8324\n",
            "Epoch 494/512\n",
            "712/712 [==============================] - 0s 34us/sample - loss: 0.4410 - accuracy: 0.8287 - val_loss: 0.3778 - val_accuracy: 0.8324\n",
            "Epoch 495/512\n",
            "712/712 [==============================] - 0s 43us/sample - loss: 0.4383 - accuracy: 0.8216 - val_loss: 0.3807 - val_accuracy: 0.8268\n",
            "Epoch 496/512\n",
            "712/712 [==============================] - 0s 39us/sample - loss: 0.4220 - accuracy: 0.8357 - val_loss: 0.3962 - val_accuracy: 0.8380\n",
            "Epoch 497/512\n",
            "712/712 [==============================] - 0s 37us/sample - loss: 0.4313 - accuracy: 0.8230 - val_loss: 0.3820 - val_accuracy: 0.8156\n",
            "Epoch 498/512\n",
            "712/712 [==============================] - 0s 39us/sample - loss: 0.4153 - accuracy: 0.8343 - val_loss: 0.3777 - val_accuracy: 0.8324\n",
            "Epoch 499/512\n",
            "712/712 [==============================] - 0s 41us/sample - loss: 0.4342 - accuracy: 0.8287 - val_loss: 0.3788 - val_accuracy: 0.8268\n",
            "Epoch 500/512\n",
            "712/712 [==============================] - 0s 41us/sample - loss: 0.4573 - accuracy: 0.8062 - val_loss: 0.3737 - val_accuracy: 0.8268\n",
            "Epoch 501/512\n",
            "712/712 [==============================] - 0s 44us/sample - loss: 0.4102 - accuracy: 0.8329 - val_loss: 0.3690 - val_accuracy: 0.8268\n",
            "Epoch 502/512\n",
            "712/712 [==============================] - 0s 38us/sample - loss: 0.4296 - accuracy: 0.8230 - val_loss: 0.3833 - val_accuracy: 0.8324\n",
            "Epoch 503/512\n",
            "712/712 [==============================] - 0s 37us/sample - loss: 0.4338 - accuracy: 0.8287 - val_loss: 0.3705 - val_accuracy: 0.8268\n",
            "Epoch 504/512\n",
            "712/712 [==============================] - 0s 39us/sample - loss: 0.4269 - accuracy: 0.8301 - val_loss: 0.3802 - val_accuracy: 0.8380\n",
            "Epoch 505/512\n",
            "712/712 [==============================] - 0s 35us/sample - loss: 0.4367 - accuracy: 0.8272 - val_loss: 0.3763 - val_accuracy: 0.8324\n",
            "Epoch 506/512\n",
            "712/712 [==============================] - 0s 38us/sample - loss: 0.4264 - accuracy: 0.8216 - val_loss: 0.3866 - val_accuracy: 0.8324\n",
            "Epoch 507/512\n",
            "712/712 [==============================] - 0s 38us/sample - loss: 0.4108 - accuracy: 0.8216 - val_loss: 0.3781 - val_accuracy: 0.8324\n",
            "Epoch 508/512\n",
            "712/712 [==============================] - 0s 34us/sample - loss: 0.4356 - accuracy: 0.8118 - val_loss: 0.3900 - val_accuracy: 0.8212\n",
            "Epoch 509/512\n",
            "712/712 [==============================] - 0s 44us/sample - loss: 0.4333 - accuracy: 0.8146 - val_loss: 0.3889 - val_accuracy: 0.8324\n",
            "Epoch 510/512\n",
            "712/712 [==============================] - 0s 42us/sample - loss: 0.4334 - accuracy: 0.8230 - val_loss: 0.3807 - val_accuracy: 0.8380\n",
            "Epoch 511/512\n",
            "712/712 [==============================] - 0s 37us/sample - loss: 0.4298 - accuracy: 0.8244 - val_loss: 0.3720 - val_accuracy: 0.8324\n",
            "Epoch 512/512\n",
            "712/712 [==============================] - 0s 43us/sample - loss: 0.4514 - accuracy: 0.8132 - val_loss: 0.3885 - val_accuracy: 0.8268\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCXmb-7H-Ldr",
        "colab_type": "text"
      },
      "source": [
        "## Plot training statistics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z5OUeZcS-Oqa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_history_info(history):\n",
        "    # get from variable \"history\"\n",
        "    acc = history.history['accuracy']\n",
        "    val_acc = history.history['val_accuracy']\n",
        "    loss = history.history['loss']\n",
        "    val_loss = history.history['val_loss']\n",
        "\n",
        "    epochs = history.epoch\n",
        "\n",
        "    plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "    plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "    plt.title('Training and validation accuracy')\n",
        "    plt.legend()\n",
        "    plt.figure()\n",
        "\n",
        "    plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "    plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "    plt.title('Training and validation loss')\n",
        "    plt.legend()\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "94c772d1-fb99-4bea-a375-a903dabc103d",
        "id": "qzkyyNBs_OAU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        }
      },
      "source": [
        "plot_history_info(training_history)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nf0fo/YlGpeuaAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rb7mHjsR-Evs",
        "colab_type": "text"
      },
      "source": [
        "## Check the final accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_K8KrVE0L5-",
        "colab_type": "code",
        "outputId": "1ad6dc2c-0499-43e1-b887-3d71d8760863",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "(test_loss, test_accuracy) = model.evaluate(test_x, test_y, batch_size=1)\n",
        "print(\"Test accuracy: {}\".format(test_accuracy))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "418/418 [==============================] - 1s 2ms/sample - loss: 0.3081 - accuracy: 0.9067\n",
            "Test accuracy: 0.9066985845565796\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RY-UXxAXRAbp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}